{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"lm-eval-so \ubb38\uc11c","text":"<p><code>lm-eval-so</code>\ub294 \ucc57\ubd07\uc744 \uccb4\uacc4\uc801\uc73c\ub85c \ud14c\uc2a4\ud2b8\u00b7\ud3c9\uac00\ud558\uae30 \uc704\ud55c \uc0c1\uc704 \ud504\ub808\uc784\uc6cc\ud06c\uc785\ub2c8\ub2e4.</p> <ul> <li>Generator</li> <li>\uc6d0\ucc9c \ub370\uc774\ud130(CSV/JSONL \ub4f1)\ub97c canonical <code>TestSample</code> \ub370\uc774\ud130\uc14b\uc73c\ub85c \ubcc0\ud658</li> <li>Runner</li> <li>Dataset \u00d7 Backend \u00d7 RunConfig \uc870\ud569\uc73c\ub85c \uc2e4\uc81c \ucc57\ubd07/\ubaa8\ub378\uc744 \ud638\ucd9c\ud558\uace0 <code>RunResult</code>\ub97c \uc218\uc9d1</li> <li>Evaluator</li> <li>RunResult + Dataset\uc744 \uae30\ubc18\uc73c\ub85c \ub2e4\uc591\ud55c \uba54\ud2b8\ub9ad(<code>EvalScore</code>)\uc744 \uacc4\uc0b0\ud558\uace0 \ub9ac\ud3ec\ud2b8 \uc0dd\uc131</li> </ul> <p>\uc774 \uc0ac\uc774\ud2b8\ub294 \uc704 \uc138 \ubaa8\ub4c8\uc744 Generator \u2192 Runner \u2192 Evaluator \uc21c\uc11c\ub85c \uc5b4\ub5bb\uac8c \uc0ac\uc6a9\ud558\ub294\uc9c0, \uadf8\ub9ac\uace0 Quick Start / CLI / API \ub808\ud37c\ub7f0\uc2a4\ub97c \uc815\ub9ac\ud55c \uc815\uc801 \ubb38\uc11c\uc785\ub2c8\ub2e4.</p>"},{"location":"#_1","title":"\ube60\ub974\uac8c \uc2dc\uc791\ud558\uae30","text":"<p>\uac00\uc7a5 \uba3c\uc800 Quick Start E2E \uc608\uc81c\ub97c \uc2e4\ud589\ud574 \ubcf4\ub294 \uac83\uc744 \ucd94\ucc9c\ud569\ub2c8\ub2e4.</p> <ul> <li>Quick Start: end-to-end \uc608\uc81c</li> <li>\ub354 \ub9ce\uc740 \uc608\uc81c (Multi-turn, Custom Metric)</li> </ul> <p>\ub85c\uceec\uc5d0\uc11c Quick Start\ub97c \ub3cc\ub9ac\uba74 \ub2e4\uc74c\uc744 \ud55c \ubc88\uc5d0 \uacbd\ud5d8\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p> <ol> <li>\uc791\uc740 toy dataset(<code>toy_support_qa</code>) \uc0dd\uc131 (Generator)</li> <li>OpenAI backend(<code>gpt-4o-mini</code> \ub4f1)\ub97c \uc0ac\uc6a9\ud55c \ucc57\ubd07 \uc2e4\ud589 (Runner)</li> <li><code>exact_match</code> / <code>keyword_coverage</code> \uba54\ud2b8\ub9ad \ud3c9\uac00 \ubc0f JSON/Markdown \ub9ac\ud3ec\ud2b8 \uc0dd\uc131 (Evaluator)</li> </ol>"},{"location":"#_2","title":"\uc0ac\uc6a9 \ubc29\ubc95 \ubb38\uc11c","text":"<p>\ubcf4\ub2e4 \uad6c\uc870\uc801\uc73c\ub85c \ud504\ub808\uc784\uc6cc\ud06c\ub97c \uc774\ud574\ud558\uace0 \uc2f6\ub2e4\uba74 \ub2e4\uc74c \ubb38\uc11c\ub97c \ucc38\uace0\ud558\uc138\uc694.</p> <ul> <li>Framework Overview</li> <li>Generator \uc0ac\uc6a9\ubc95</li> <li>Runner \uc0ac\uc6a9\ubc95</li> <li>Evaluator \uc0ac\uc6a9\ubc95</li> </ul>"},{"location":"#_3","title":"\ub808\ud37c\ub7f0\uc2a4","text":"<ul> <li>CLI \ub808\ud37c\ub7f0\uc2a4</li> <li>API \ub808\ud37c\ub7f0\uc2a4 \u2014 Core \ub3c4\uba54\uc778 \ubaa8\ub378(<code>TestSample</code>, <code>RunConfig</code>, <code>RunResult</code>, <code>EvalScore</code>, <code>EvaluationReport</code> \ub4f1)\uc744 mkdocstrings\ub85c \uc790\ub3d9 \ubb38\uc11c\ud654\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</li> </ul>"},{"location":"#_4","title":"\uc18c\uc2a4 \ucf54\ub4dc","text":"<ul> <li>GitHub: https://github.com/mackim-3768/lm-eval-so</li> </ul>"},{"location":"reference/api/","title":"API \ub808\ud37c\ub7f0\uc2a4 (\uac1c\uc694)","text":"<p>\uc774 \ubb38\uc11c\ub294 <code>lm-eval-so</code>\uc758 \ud575\uc2ec Python API\ub97c \uc790\ub3d9 \ubb38\uc11c\ud654\ud558\uae30 \uc704\ud55c \uc9c4\uc785\uc810\uc785\ub2c8\ub2e4. mkdocstrings \ud50c\ub7ec\uadf8\uc778\uc744 \ud65c\uc6a9\ud558\uba74, \uc544\ub798\uc640 \uac19\uc774 \ubaa8\ub4c8/\ud074\ub798\uc2a4\uc5d0 \ub300\ud55c \uc0c1\uc138 \ubb38\uc11c\ub97c \uc0dd\uc131\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p> <p>\uc2e4\uc81c mkdocstrings \ube14\ub85d\uc740 \ud504\ub85c\uc81d\ud2b8 \uc0c1\ud669\uc5d0 \ub9de\uac8c \uc870\uc815\ud558\uba74 \ub429\ub2c8\ub2e4.</p>"},{"location":"reference/api/#core","title":"Core \ub3c4\uba54\uc778 \ubaa8\ub378","text":"<p>\uc608\uc2dc:</p> <pre><code>::: lm_eval_so.evaluator.domain.TestSampleRecord\n\n::: lm_eval_so.evaluator.domain.RunRecord\n\n::: lm_eval_so.evaluator.domain.EvalScore\n\n::: lm_eval_so.evaluator.domain.EvaluationResult\n\n::: lm_eval_so.evaluator.domain.EvaluationReport\n</code></pre>"},{"location":"reference/api/#runner","title":"Runner \ubaa8\ub378","text":"<pre><code>::: lm_eval_so.runner.models.TestSample\n\n::: lm_eval_so.runner.models.RunConfig\n\n::: lm_eval_so.runner.models.RunResult\n</code></pre>"},{"location":"reference/api/#generator","title":"Generator \ud0c0\uc785","text":"<pre><code>::: lm_eval_so.generator.types.TestSample\n</code></pre> <p>\uc704\uc640 \uac19\uc740 mkdocstrings \uc9c0\uc2dc\ubb38\uc744 \uc0ac\uc6a9\ud558\uba74, <code>mkdocs build</code> \uc2dc\uc810\uc5d0 docstring/\ud0c0\uc785 \uc815\ubcf4\ub97c \uae30\ubc18\uc73c\ub85c API \ubb38\uc11c\uac00 \uc790\ub3d9 \uc0dd\uc131\ub429\ub2c8\ub2e4.</p> <p>\ud504\ub85c\uc81d\ud2b8\uc5d0 \ub9de\uac8c \ud3ec\ud568\ud560 \ubaa8\ub378/\ud568\uc218/\ud074\ub798\uc2a4\ub97c \uc120\ubcc4\ud574\uc11c \ucd94\uac00\ud574 \uc8fc\uc138\uc694.</p>"},{"location":"reference/cli/","title":"CLI \ub808\ud37c\ub7f0\uc2a4","text":"<p>\uc774 \ubb38\uc11c\ub294 <code>lm-eval-so</code>\uc5d0\uc11c \uc81c\uacf5\ud558\ub294 \uc8fc\uc694 CLI \uc5d4\ud2b8\ub9ac\ud3ec\uc778\ud2b8\ub97c \uc815\ub9ac\ud569\ub2c8\ub2e4.</p> <p>\uac01 CLI\ub294 <code>python -m \ubaa8\ub4c8\uba85</code> \ud615\ud0dc\ub85c \ud638\ucd9c\ud558\ub294 \uac83\uc744 \uae30\uc900\uc73c\ub85c \ud569\ub2c8\ub2e4.</p>"},{"location":"reference/cli/#1-generator-cli","title":"1. Generator CLI","text":"<p>\uc5d4\ud2b8\ub9ac\ud3ec\uc778\ud2b8:</p> <pre><code>python -m lm_eval_so.generator.cli --help\n</code></pre> <p>\uc8fc\uc694 \uc635\uc158 \uc694\uc57d:</p> <ul> <li><code>--input</code>: \uc785\ub825 \ud30c\uc77c \uacbd\ub85c (CSV/JSONL)</li> <li><code>--input-format</code>: <code>csv</code> \ub610\ub294 <code>jsonl</code> (\uc0dd\ub7b5 \uc2dc \ud655\uc7a5\uc790 \uae30\ubc18 \uc790\ub3d9 \ucd94\ub860)</li> <li><code>--output-dir</code>: \ucd9c\ub825 \ub514\ub809\ud130\ub9ac (\ud544\uc218)</li> <li><code>--dataset-id</code>, <code>--name</code>, <code>--version</code>: Dataset \uba54\ud0c0\ub370\uc774\ud130</li> <li>CSV \uceec\ub7fc \ub9e4\ud551</li> <li><code>--csv-user-col</code>, <code>--csv-expected-col</code>, <code>--csv-system-col</code></li> <li><code>--csv-tags-col</code>, <code>--csv-tags-sep</code>, <code>--csv-language-col</code></li> <li>\ud544\ud130/\uc0d8\ud50c\ub9c1</li> <li><code>--min-len</code>, <code>--max-len</code></li> <li><code>--sample-size</code>, <code>--sample-random</code></li> </ul> <p>\ubcf4\ub2e4 \uc790\uc138\ud55c \uc608\uc2dc\ub294 Generator \uc0ac\uc6a9\ubc95 \ubb38\uc11c\ub97c \ucc38\uace0\ud558\uc138\uc694.</p>"},{"location":"reference/cli/#2-runner-cli","title":"2. Runner CLI","text":"<p>\uc5d4\ud2b8\ub9ac\ud3ec\uc778\ud2b8:</p> <pre><code>python -m lm_eval_so.runner.cli --help\n</code></pre> <p>\uc8fc\uc694 \uc635\uc158 \uc694\uc57d:</p> <ul> <li>Dataset</li> <li><code>--dataset</code>: Dataset JSONL \ub610\ub294 Dataset \ub514\ub809\ud130\ub9ac \uacbd\ub85c</li> <li><code>--metadata</code>: <code>metadata.json</code> \uacbd\ub85c (\ud544\uc694 \uc2dc)</li> <li>Backend/RunConfig</li> <li><code>--backend</code>: backend \uc774\ub984 (\uc608: <code>openai</code>)</li> <li><code>--model</code>: \ubaa8\ub378 \uc774\ub984/ID (\uc608: <code>gpt-4o-mini</code>)</li> <li><code>--param key=value</code>: RunConfig.parameters \uc5d0 \uc804\ub2ec (\ubc18\ubcf5 \uc0ac\uc6a9 \uac00\ub2a5)</li> <li><code>--backend-opt key=value</code>: backend-specific \uc635\uc158</li> <li>Runner \uc635\uc158</li> <li><code>--max-concurrency</code>, <code>--timeout</code>, <code>--max-retries</code>, <code>--rate-limit</code>, <code>--trace-prefix</code></li> <li>\ucd9c\ub825</li> <li><code>--output-dir</code>: \uacb0\uacfc \ud30c\uc77c(JSONL \ubc0f \uba54\ud0c0\ub370\uc774\ud130)\uc744 \uc800\uc7a5\ud560 \ub514\ub809\ud130\ub9ac</li> </ul> <p>\ubcf4\ub2e4 \uc790\uc138\ud55c \uc608\uc2dc\ub294 Runner \uc0ac\uc6a9\ubc95 \ubb38\uc11c\ub97c \ucc38\uace0\ud558\uc138\uc694.</p>"},{"location":"reference/cli/#3-evaluator-cli","title":"3. Evaluator CLI","text":"<p>\uc5d4\ud2b8\ub9ac\ud3ec\uc778\ud2b8:</p> <pre><code>python -m lm_eval_so.evaluator.cli --help\n</code></pre> <p>\uc8fc\uc694 \uc635\uc158 \uc694\uc57d:</p> <ul> <li>\uc785\ub825</li> <li><code>--dataset</code>: canonical <code>TestSample</code> JSONL \uacbd\ub85c</li> <li><code>--metadata</code>: Dataset \uba54\ud0c0\ub370\uc774\ud130 JSON \uacbd\ub85c</li> <li><code>--runs</code>: <code>RunResult</code> JSONL \uacbd\ub85c</li> <li>\uc124\uc815</li> <li><code>--config</code>: Evaluator \uc124\uc815 \ud30c\uc77c(YAML/JSON)</li> <li><code>--plugin</code>: \uc0ac\uc6a9\uc790 \uc815\uc758 Metric \ud50c\ub7ec\uadf8\uc778 \uacbd\ub85c (Python \ud30c\uc77c \ub610\ub294 \ubaa8\ub4c8\uba85, \ubc18\ubcf5 \uc0ac\uc6a9 \uac00\ub2a5)</li> <li>\ucd9c\ub825</li> <li><code>--output</code>: \ub9ac\ud3ec\ud2b8 \ucd9c\ub825 \ub514\ub809\ud130\ub9ac</li> <li>\ud3ec\ub9f7 \uc81c\uc5b4</li> <li><code>--no-json</code>: JSON summary/scores \uc0dd\ub7b5</li> <li><code>--no-markdown</code>: Markdown \ub9ac\ud3ec\ud2b8 \uc0dd\ub7b5</li> </ul> <p>\ubcf4\ub2e4 \uc790\uc138\ud55c \uc608\uc2dc\ub294 Evaluator \uc0ac\uc6a9\ubc95 \ubb38\uc11c\ub97c \ucc38\uace0\ud558\uc138\uc694.</p>"},{"location":"reference/cli/#4","title":"4. \uae30\ud0c0","text":"<p>\ud5a5\ud6c4 <code>lm_eval_so.*</code> \ud328\ud0a4\uc9c0\uc5d0 \ucd94\uac00 CLI\uac00 \ub4e4\uc5b4\uac00\uba74, \uc774 \ubb38\uc11c\uc5d0 \ud568\uaed8 \uc815\ub9ac\ud574 \ub458 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p>"},{"location":"usage/evaluator/","title":"Evaluator \uc0ac\uc6a9\ubc95","text":"<p>\uc774 \ubb38\uc11c\ub294 Dataset + RunResult\ub97c \uae30\ubc18\uc73c\ub85c \uba54\ud2b8\ub9ad\uc744 \uacc4\uc0b0\ud558\uace0 \ub9ac\ud3ec\ud2b8\ub97c \uc0dd\uc131\ud558\ub294 Evaluator \ubaa8\ub4c8 \uc0ac\uc6a9 \ubc29\ubc95\uc744 \uc815\ub9ac\ud569\ub2c8\ub2e4.</p>"},{"location":"usage/evaluator/#1","title":"1. \uc5ed\ud560","text":"<p>Evaluator\ub294 \ub2e4\uc74c\uc744 \ub2f4\ub2f9\ud569\ub2c8\ub2e4.</p> <ol> <li>Dataset(<code>TestSample</code>), RunResult\ub97c sample_id \uae30\uc900\uc73c\ub85c \uc870\uc778</li> <li>\uc124\uc815\ub41c metrics\ub97c \uc2e4\ud589\ud558\uc5ec \uac01 \uc0d8\ud50c\uc5d0 \ub300\ud55c <code>EvalScore</code> \uacc4\uc0b0</li> <li>metric\ubcc4 \ud1b5\uacc4(\ud3c9\uade0, \ud45c\uc900\ud3b8\ucc28, sample_count) \ubc0f breakdown(tag/language/length \ub4f1) \uc0dd\uc131</li> <li>LLM Judge \uae30\ubc18 \ud3c9\uac00 \uacb0\uacfc \uc694\uc57d(optional)</li> <li>JSON/Markdown \ub4f1 \uc0ac\ub78c/\uba38\uc2e0 \uce5c\ud654\uc801\uc778 \ub9ac\ud3ec\ud2b8 \ud30c\uc77c \uc0dd\uc131</li> </ol>"},{"location":"usage/evaluator/#2-cli","title":"2. CLI \uac1c\uc694","text":"<p>Evaluator\ub294 <code>python -m lm_eval_so.evaluator.cli</code> \ud615\ud0dc\uc758 CLI \uc5d4\ud2b8\ub9ac\ud3ec\uc778\ud2b8\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4.</p> <pre><code>python -m lm_eval_so.evaluator.cli --help\n</code></pre> <p>\uc8fc\uc694 \uc778\uc790:</p> <ul> <li>\uc785\ub825 \ub370\uc774\ud130</li> <li><code>--dataset</code>: canonical <code>TestSample</code> JSONL \uacbd\ub85c (\uc608: <code>test.jsonl</code>)</li> <li><code>--metadata</code>: Dataset \uba54\ud0c0\ub370\uc774\ud130 JSON \uacbd\ub85c (\uc608: <code>metadata.json</code>)</li> <li><code>--runs</code>: <code>RunResult</code> JSONL \uacbd\ub85c (\uc608: <code>run_results.jsonl</code>)</li> <li>\uc124\uc815</li> <li><code>--config</code>: Evaluator \uc124\uc815 \ud30c\uc77c(YAML/JSON)</li> <li>\ucd9c\ub825</li> <li><code>--output</code>: \ub9ac\ud3ec\ud2b8 \ucd9c\ub825 \ub514\ub809\ud130\ub9ac</li> <li>\ud3ec\ub9f7 \uc81c\uc5b4</li> <li><code>--no-markdown</code>: Markdown \ub9ac\ud3ec\ud2b8 \uc0dd\ub7b5</li> <li><code>--no-json</code>: JSON summary/scores \uc0dd\ub7b5</li> </ul>"},{"location":"usage/evaluator/#3-evaluator-eval_toyyaml","title":"3. Evaluator \uc124\uc815 \ud30c\uc77c \uad6c\uc870 (\uc608: eval_toy.yaml)","text":"<p>\uae30\ubcf8 \uad6c\uc870\ub294 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4.</p> <pre><code>run_config:\n  backend: openai\n  model: gpt-4o-mini\n\nmetrics:\n  - type: exact_match\n    name: exact_match\n    parameters:\n      normalize_whitespace: true\n      case_sensitive: false\n\n  - type: keyword_coverage\n    name: keyword_coverage\n    parameters:\n      keywords:\n        - \"\ube44\ubc00\ubc88\ud638\"\n        - \"\uc694\uae08\uc81c\"\n        - \"export\"\n      case_sensitive: false\n\nbreakdown:\n  dimensions:\n    - tag\n    - language\n    - length\n\nreport:\n  formats:\n    - json\n    - markdown\n\nmin_samples: 1\n</code></pre> <ul> <li><code>run_config</code></li> <li>\uc774 \ud3c9\uac00\uac00 \uc5b4\ub5a4 RunConfig \ud658\uacbd\uc744 \ub300\uc0c1\uc73c\ub85c \ud558\ub294\uc9c0 \uba54\ud0c0 \uc815\ubcf4\ub97c \uae30\ub85d (\uc2e4\uc81c \uc2e4\ud589\uacfc \uc9c1\uc811 \uc5f0\ub3d9\ub418\uc9c4 \uc54a\uc9c0\ub9cc, \ub9ac\ud3ec\ud2b8\uc5d0 \ud3ec\ud568\ub428)</li> <li><code>metrics</code></li> <li>\uc0ac\uc6a9\ud560 metric\ub4e4\uc758 \ud0c0\uc785/\uc774\ub984/\ud30c\ub77c\ubbf8\ud130</li> <li>type\uc740 registry\uc5d0 \ub4f1\ub85d\ub41c metric \uc774\ub984 (<code>exact_match</code>, <code>keyword_coverage</code>, <code>llm_judge</code> \ub4f1)</li> <li><code>breakdown</code></li> <li>tag/language/length \ub4f1 \ud2b9\uc815 dimension\ubcc4\ub85c \uc810\uc218\ub97c \ub098\ub220 \ubcf4\uace0 \uc2f6\uc744 \ub54c \uc0ac\uc6a9</li> <li><code>report</code></li> <li>\uc5b4\ub5a4 \ud3ec\ub9f7(JSON/Markdown \ub4f1)\uc73c\ub85c \ub9ac\ud3ec\ud2b8\ub97c \uc0dd\uc131\ud560\uc9c0</li> <li><code>min_samples</code></li> <li>\ud3c9\uac00\ub97c \uc9c4\ud589\ud558\uae30 \uc704\ud55c \ucd5c\uc18c \uc0d8\ud50c \uc218 (\ub108\ubb34 \uc801\uc73c\uba74 \uc2a4\ud0b5\ud558\ub3c4\ub85d \ubc29\uc5b4)</li> </ul>"},{"location":"usage/evaluator/#4-quick-start","title":"4. Quick Start \uc608\uc81c \uc2e4\ud589","text":"<p>Quick Start\uc5d0\uc11c Evaluator\ub294 \ub2e4\uc74c\uacfc \uac19\uc774 \uc2e4\ud589\ub429\ub2c8\ub2e4.</p> <pre><code>python -m lm_eval_so.evaluator.cli \\\n  --dataset example/quickstart/dataset/toy_support_qa_v1/test.jsonl \\\n  --metadata example/quickstart/dataset/toy_support_qa_v1/metadata.json \\\n  --runs example/quickstart/runs/openai_gpt-4o-mini/run_results.jsonl \\\n  --config example/quickstart/config/eval_toy.yaml \\\n  --output example/quickstart/reports\n</code></pre> <p>\uc2e4\ud589 \uacb0\uacfc \uc608:</p> <ul> <li><code>example/quickstart/reports/summary.json</code></li> <li><code>example/quickstart/reports/scores.jsonl</code></li> <li><code>example/quickstart/reports/report.md</code></li> </ul>"},{"location":"usage/evaluator/#5-metric","title":"5. Metric \uc885\ub958 \uc608\uc2dc","text":"<p>\uae30\ubcf8 \uc81c\uacf5 metric\ub4e4\uc740 \ub300\ub7b5 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4.</p> <ul> <li>exact_match</li> <li>expected \ud14d\uc2a4\ud2b8\uc640 \ubaa8\ub378 \uc751\ub2f5\uc774 (\uacf5\ubc31 \uc815\uaddc\ud654/\ub300\uc18c\ubb38\uc790 \uc635\uc158\uc5d0 \ub530\ub77c) \uc815\ud655\ud788 \uc77c\uce58\ud558\ub294\uc9c0 \ud3c9\uac00</li> <li>\uacb0\uacfc: 0.0 \ub610\ub294 1.0</li> <li>keyword_coverage</li> <li>\uc124\uc815\ub41c keywords \ub9ac\uc2a4\ud2b8 \uc911 \uc751\ub2f5\uc5d0 \ud3ec\ud568\ub41c \ube44\uc728\uc744 \ud3c9\uac00 (0.0 ~ 1.0)</li> <li>llm_judge</li> <li>\uc678\ubd80 LLM\uc774 \ubbf8\ub9ac \ud3c9\uac00\ud574 \ub454 \uc810\uc218(\uc608: <code>run.raw[\"llm_judge\"][\"score\"]</code>)\ub97c \uc77d\uc5b4\uc640 0~1\ub85c \uc815\uaddc\ud654</li> <li>\uc678\ubd80 LLM\uc774 \ubbf8\ub9ac \ud3c9\uac00\ud574 \ub454 \uc810\uc218(\uc608: <code>run.raw[\"llm_judge\"][\"score\"]</code>)\ub97c \uc77d\uc5b4\uc640 0~1\ub85c \uc815\uaddc\ud654</li> <li>\uc2e4\uc81c LLM \ud638\ucd9c\uc740 \ud558\uc9c0 \uc54a\uace0, Runner/\uc678\ubd80 \ud30c\uc774\ud504\ub77c\uc778\uc774 \uc0dd\uc131\ud55c \uacb0\uacfc\ub97c \uc18c\ube44\ud558\ub294 \ud615\ud0dc</li> <li>tool_call_match</li> <li>\ubaa8\ub378\uc758 \ud568\uc218 \ud638\ucd9c(JSON)\uc774 \uc608\uc0c1\ub41c \ud638\ucd9c(JSON)\uacfc \uc77c\uce58\ud558\ub294\uc9c0 \ud3c9\uac00</li> <li><code>allow_order_mismatch</code>: \uc21c\uc11c \ubb34\uc2dc \uc5ec\ubd80 (\uae30\ubcf8\uac12: False)</li> <li><code>exclude_args</code>: \ube44\uad50\uc5d0\uc11c \uc81c\uc678\ud560 \uc778\uc790 \ubaa9\ub85d (\uc608: timestamp \ub4f1)</li> </ul>"},{"location":"usage/evaluator/#6-custom-metric","title":"6. Custom Metric (\ud50c\ub7ec\uadf8\uc778) \uc0ac\uc6a9","text":"<p>\uae30\ubcf8 \uc81c\uacf5 Metric \uc678\uc5d0, \uc0ac\uc6a9\uc790\uac00 \uc9c1\uc811 \ud30c\uc774\uc36c \ucf54\ub4dc\ub85c \uc791\uc131\ud55c Metric\uc744 \uc0ac\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p>"},{"location":"usage/evaluator/#61","title":"6.1 \ud50c\ub7ec\uadf8\uc778 \uc791\uc131","text":"<p><code>lm_eval_so.evaluator.metrics.Metric</code>\uc744 \uc0c1\uc18d\ubc1b\uc544 \uad6c\ud604\ud558\uace0, <code>register_metrics</code> \ud568\uc218\ub97c \ud1b5\ud574 \ub4f1\ub85d\ud569\ub2c8\ub2e4.</p> <pre><code># my_plugin.py\nfrom lm_eval_so.evaluator.metrics import Metric, MetricResult\n\nclass MyMetric(Metric):\n    def score(self, sample, run):\n        # ... \ud3c9\uac00 \ub85c\uc9c1 ...\n        return self.make_score(sample, value=1.0, detail={})\n\ndef register_metrics(registry):\n    registry.register(\"my_metric\", lambda cfg: MyMetric(**cfg))\n</code></pre>"},{"location":"usage/evaluator/#62","title":"6.2 \ud50c\ub7ec\uadf8\uc778 \ub85c\ub4dc \ubc0f \uc2e4\ud589","text":"<p>Evaluator CLI \uc2e4\ud589 \uc2dc <code>--plugin</code> \uc635\uc158\uc73c\ub85c \uacbd\ub85c\ub97c \uc9c0\uc815\ud569\ub2c8\ub2e4.</p> <pre><code>python -m lm_eval_so.evaluator.cli \\\n  ... \\\n  --plugin path/to/my_plugin.py\n</code></pre>"},{"location":"usage/evaluator/#63","title":"6.3 \uc124\uc815 \ud30c\uc77c \ubc18\uc601","text":"<p>\uc124\uc815 \ud30c\uc77c(<code>config.yaml</code>)\uc5d0\uc11c \ub4f1\ub85d\ud55c <code>type</code> \uc774\ub984\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4.</p> <pre><code>metrics:\n  - type: my_metric\n    name: custom_check\n    parameters:\n      threshold: 0.5\n</code></pre> <p>\uc790\uc138\ud55c \uc608\uc81c\ub294 More Examples (Custom Metrics) \ubb38\uc11c\ub97c \ucc38\uace0\ud558\uc138\uc694.</p>"},{"location":"usage/evaluator/#7-report","title":"7. Report \uc77d\ub294 \ubc95","text":"<p>Evaluator\uac00 \uc0dd\uc131\ud558\ub294 \ub9ac\ud3ec\ud2b8\uc5d0\ub294 \ubcf4\ud1b5 \ub2e4\uc74c \uc815\ubcf4\uac00 \ud3ec\ud568\ub429\ub2c8\ub2e4.</p> <ul> <li>Experiment metadata</li> <li>dataset \uc815\ubcf4 (id/name/version, sample_count \ub4f1)</li> <li>run_config (backend, model, \ud30c\ub77c\ubbf8\ud130)</li> <li>evaluator_config (metrics/breakdown/report \uc124\uc815)</li> <li>Metrics summary</li> <li>metric\ubcc4 <code>mean</code>, <code>std</code>, <code>sample_count</code> \ud14c\uc774\ube14</li> <li>Breakdown</li> <li>tag / language / length \ubcc4 metric \ubd84\ud3ec</li> <li>Error cases</li> <li>RunResult.status\uac00 ok\uac00 \uc544\ub2cc \uc0d8\ud50c\ub4e4\uc758 \uc694\uc57d</li> <li>LLM Judge detail (\uc0ac\uc6a9\ud55c \uacbd\uc6b0)</li> <li>prompt_id, prompt_version, \ud3c9\uac00 \uae30\uc900(criteria), \ud3c9\uac00\uc5d0 \uc0ac\uc6a9\ub41c \uc0d8\ud50c \uc9d1\ud569 \ub4f1</li> </ul> <p>\uc774 \uad6c\uc870\ub97c \uae30\uc900\uc73c\ub85c \uc5ec\ub7ec \uc2e4\ud5d8/\ubaa8\ub378\uc744 \ube44\uad50\ud558\ub294 \uace0\uc218\uc900 \ub9ac\ud3ec\ud2b8\ub97c \uc190\uc27d\uac8c \ub9cc\ub4e4 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p>"},{"location":"usage/examples/","title":"\ucd94\uac00 \uc608\uc81c (Examples)","text":"<p><code>lm-eval-so</code> \ub9ac\ud3ec\uc9c0\ud1a0\ub9ac\uc758 <code>example/</code> \ub514\ub809\ud130\ub9ac\uc5d0\ub294 Quick Start \uc678\uc5d0\ub3c4 \ub2e4\uc591\ud55c \uc0ac\uc6a9 \uc0ac\ub840\ub97c \ubcf4\uc5ec\uc8fc\ub294 \uc608\uc81c\ub4e4\uc774 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.</p> <p>\uc774 \ubb38\uc11c\ub294 \uac01 \uc608\uc81c\uc758 \ubaa9\uc801\uacfc \uc2e4\ud589 \ubc29\ubc95\uc744 \uc124\uba85\ud569\ub2c8\ub2e4.</p>"},{"location":"usage/examples/#1-multi-turn-chat-multiturn_chat","title":"1. Multi-turn Chat (<code>multiturn_chat/</code>)","text":"<p>\ub2e8\ubc1c\uc131 \uc9c8\uc758\uc751\ub2f5\uc774 \uc544\ub2cc, \ub300\ud654\uc758 \ubb38\ub9e5(Context) \uc744 \uc720\uc9c0\ud558\uba70 \ud14c\uc2a4\ud2b8\ud558\ub294 \ubc29\ubc95\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.</p> <ul> <li>\uc704\uce58: <code>example/multiturn_chat/</code></li> <li>\uc8fc\uc694 \ud2b9\uc9d5:<ul> <li>JSON \uae30\ubc18 \ub370\uc774\ud130\uc14b \uc785\ub825 (<code>messages</code> \ub9ac\uc2a4\ud2b8 \uad6c\uc870)</li> <li>Runner\uc758 \uba40\ud2f0\ud134 \ucee8\ud14d\uc2a4\ud2b8 \ucc98\ub9ac \ud655\uc778</li> <li><code>run_multiturn.sh</code> \uc2a4\ud06c\ub9bd\ud2b8\ub85c \ub370\uc774\ud130\uc14b \uc0dd\uc131\ubd80\ud130 \ud3c9\uac00\uae4c\uc9c0 \uc218\ud589</li> </ul> </li> </ul>"},{"location":"usage/examples/#_1","title":"\uc2e4\ud589 \ubc29\ubc95","text":"<pre><code># OPENAI_API_KEY \uc124\uc815 \ud544\uc694\nexport OPENAI_API_KEY=\"sk-...\"\n\nbash example/multiturn_chat/run_multiturn.sh\n</code></pre>"},{"location":"usage/examples/#_2","title":"\ub370\uc774\ud130\uc14b \uad6c\uc870 \uc608\uc2dc","text":"<p><code>example/multiturn_chat/data/conversations.json</code>:</p> <pre><code>[\n  {\n    \"id\": \"mt_001\",\n    \"messages\": [\n      {\"role\": \"user\", \"content\": \"Hi, I need help with my order.\"},\n      {\"role\": \"assistant\", \"content\": \"Sure, what is your order ID?\"},\n      {\"role\": \"user\", \"content\": \"It's ORDER-123.\"}\n    ],\n    \"expected\": \"I see your order ORDER-123 is currently in transit.\",\n    \"tags\": [\"support\", \"tracking\"],\n    \"lang\": \"en\"\n  }\n]\n</code></pre> <p>Runner\ub294 \uc774 <code>messages</code>\ub97c \uc21c\uc11c\ub300\ub85c \ubc31\uc5d4\ub4dc\uc5d0 \uc804\ub2ec\ud558\uc5ec \ub300\ud654 \ud750\ub984\uc744 \uc7ac\ud604\ud569\ub2c8\ub2e4.</p>"},{"location":"usage/examples/#2-custom-metrics-custom_metric","title":"2. Custom Metrics (<code>custom_metric/</code>)","text":"<p>\uae30\ubcf8 \uc81c\uacf5 Metric(Exact Match, LLM Judge \ub4f1) \uc678\uc5d0, \uc0ac\uc6a9\uc790\uac00 \uc9c1\uc811 \ud30c\uc774\uc36c \ucf54\ub4dc\ub85c \uc791\uc131\ud55c Metric\uc744 \ud50c\ub7ec\uadf8\uc778 \ud615\ud0dc\ub85c \ub85c\ub4dc\ud558\uc5ec \uc0ac\uc6a9\ud558\ub294 \ubc29\ubc95\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.</p> <ul> <li>\uc704\uce58: <code>example/custom_metric/</code></li> <li>\uc8fc\uc694 \ud2b9\uc9d5:<ul> <li>\uc0ac\uc6a9\uc790 \uc815\uc758 Metric \uad6c\ud604 (<code>plugins/keyword_metric.py</code>)</li> <li><code>KeywordPresenceMetric</code> \ud074\ub798\uc2a4\uc640 <code>register_metrics</code> \ud568\uc218</li> <li>Evaluator CLI\uc758 <code>--plugin</code> \uc635\uc158\uc744 \ud1b5\ud55c \ub3d9\uc801 \ub85c\ub529</li> <li><code>run_custom_metric.sh</code> \uc2a4\ud06c\ub9bd\ud2b8\ub85c \uc2e4\ud589</li> </ul> </li> </ul>"},{"location":"usage/examples/#_3","title":"\uc2e4\ud589 \ubc29\ubc95","text":"<pre><code># OPENAI_API_KEY \uc124\uc815 \ud544\uc694\nbash example/custom_metric/run_custom_metric.sh\n</code></pre>"},{"location":"usage/examples/#_4","title":"\ud50c\ub7ec\uadf8\uc778 \ucf54\ub4dc \uc608\uc2dc","text":"<p><code>example/custom_metric/plugins/keyword_metric.py</code>:</p> <pre><code>from lm_eval_so.evaluator.metrics import Metric, MetricResult\n\nclass KeywordPresenceMetric(Metric):\n    def __init__(self, keywords: list[str]):\n        self.keywords = keywords\n\n    def evaluate(self, response: str, reference: str | None = None, **kwargs) -&gt; MetricResult:\n        # ... \uad6c\ud604 \ub85c\uc9c1 ...\n        return MetricResult(score=score, details=...)\n\ndef make_keyword_metric(config):\n    return KeywordPresenceMetric(keywords=config.get(\"keywords\", []))\n\ndef register_metrics(registry):\n    # Evaluator\uac00 \ud50c\ub7ec\uadf8\uc778\uc744 \ub85c\ub4dc\ud560 \ub54c \ud638\ucd9c\n    registry.register(\"keyword_presence\", make_keyword_metric)\n</code></pre>"},{"location":"usage/examples/#evaluator","title":"Evaluator \uc124\uc815 \uc608\uc2dc","text":"<p><code>example/custom_metric/config/eval_config.yaml</code>:</p> <pre><code>metrics:\n  - type: keyword_presence  # \ud50c\ub7ec\uadf8\uc778\uc5d0\uc11c \ub4f1\ub85d\ud55c \uc774\ub984\n    keywords: [\"hello\", \"world\"]\n</code></pre> <p>\uc774 \uc608\uc81c\ub97c \ud1b5\ud574 \ud504\ub85c\uc81d\ud2b8 \uace0\uc720\uc758 \ud3c9\uac00 \ub85c\uc9c1\uc744 \uc190\uc27d\uac8c \ucd94\uac00\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p>"},{"location":"usage/extending-backends/","title":"Backend \ud655\uc7a5 \uac00\uc774\ub4dc (\uc0c8 Backend \ucd94\uac00\ud558\uae30)","text":"<p>\uc774 \ubb38\uc11c\ub294 Runner \ubaa8\ub4c8\uc5d0 \uc0c8 Backend(\ubaa8\ub378/\uc5d4\ub4dc\ud3ec\uc778\ud2b8) \ub97c \ucd94\uac00\ud558\ub294 \ubc29\ubc95\uc744 \uc815\ub9ac\ud569\ub2c8\ub2e4.</p> <ul> <li><code>ChatBackend</code> \uc778\ud130\ud398\uc774\uc2a4 \uac1c\ub150</li> <li>OpenAI Backend \uad6c\ud604 \uad6c\uc870</li> <li>timeout / retry / rate-limit / \ub85c\uae45 \ubca0\uc2a4\ud2b8 \ud504\ub799\ud2f0\uc2a4</li> </ul> <p>\uc2e4\uc81c \uad6c\ud604 \ucf54\ub4dc\ub294 <code>src/lm_eval_so/core/backends/</code> \uc640 <code>src/lm_eval_so/core/backends/base.py</code> \ub97c \ud568\uaed8 \ucc38\uace0\ud558\uc138\uc694.</p>"},{"location":"usage/extending-backends/#1-chatbackend","title":"1. ChatBackend \uc778\ud130\ud398\uc774\uc2a4 \uac1c\ub150","text":"<p>Runner\ub294 \ub2e4\uc74c \uac1c\ub150 \uc704\uc5d0\uc11c \ub3d9\uc791\ud569\ub2c8\ub2e4.</p> <ul> <li>Dataset: <code>TestSample</code> \ub9ac\uc2a4\ud2b8 (\uc785\ub825 \uba54\uc2dc\uc9c0/expected/tags/metadata \ud3ec\ud568)</li> <li>RunConfig: \uc5b4\ub5a4 backend/\ubaa8\ub378/\ud30c\ub77c\ubbf8\ud130\ub85c \uc2e4\ud589\ud560\uc9c0\uc5d0 \ub300\ud55c \uc124\uc815</li> <li>ChatBackend: \uc2e4\uc81c \uc678\ubd80 \uc2dc\uc2a4\ud15c(API/\ub85c\uceec \ubaa8\ub378/ADB \ub4f1)\uc5d0 \uc694\uccad\uc744 \ubcf4\ub0b4\ub294 \uc5b4\ub311\ud130</li> </ul> <p><code>ChatBackend</code>\ub294 \ub300\ub7b5 \ub2e4\uc74c\uacfc \uac19\uc740 \uc778\ud130\ud398\uc774\uc2a4\ub97c \uac00\uc9d1\ub2c8\ub2e4.</p> <pre><code>class ChatBackend(Protocol):\n    async def send(self, request: RunRequest) -&gt; ChatResponse:\n        ...\n</code></pre> <ul> <li><code>RunRequest</code></li> <li><code>sample</code>: \uc2e4\ud589 \ub300\uc0c1 <code>TestSample</code></li> <li><code>run_config</code>: backend/\ubaa8\ub378/\ud30c\ub77c\ubbf8\ud130 \uc815\ubcf4</li> <li><code>dataset_info</code>: dataset \uba54\ud0c0\ub370\uc774\ud130</li> <li><code>trace_id</code>, <code>attempt</code>, <code>timeout_seconds</code> \ub4f1 \uc2e4\ud589 \ucee8\ud14d\uc2a4\ud2b8</li> <li><code>ChatResponse</code></li> <li><code>text</code>: \ubaa8\ub378 \uc751\ub2f5 \ud14d\uc2a4\ud2b8</li> <li><code>usage</code>: \ud1a0\ud070 \uc0ac\uc6a9\ub7c9 \uc815\ubcf4(optional)</li> <li><code>status_code</code>, <code>headers</code>, <code>raw</code>(\uc6d0\ubcf8 \uc751\ub2f5 payload) \ub4f1</li> </ul> <p>Backend \uad6c\ud604\uccb4\ub294 \uc774 \uc778\ud130\ud398\uc774\uc2a4\ub97c \ub9cc\uc871\ud558\uba70, \uc5d0\ub7ec \uc0c1\ud669\uc5d0\uc11c\ub294 <code>BackendError</code> \uc608\uc678\ub97c \uc77c\uad00\ub41c \ubc29\uc2dd\uc73c\ub85c \ub358\uc838\uc57c \ud569\ub2c8\ub2e4.</p>"},{"location":"usage/extending-backends/#2-openai-backend","title":"2. OpenAI Backend \uc608\uc2dc \uad6c\uc870","text":"<p>OpenAI Backend(\uc608: <code>openai_backend.py</code>)\ub294 <code>AsyncOpenAI</code> \ud074\ub77c\uc774\uc5b8\ud2b8\ub97c \uac10\uc2fc \uc5b4\ub311\ud130\uc785\ub2c8\ub2e4.</p> <p>\ud575\uc2ec \ud3ec\uc778\ud2b8:</p> <ul> <li>Backend \ub4f1\ub85d</li> </ul> <p><code>python   @register_backend(\"openai\")   class OpenAIChatBackend(ChatBackend):       ...</code></p> <ul> <li><code>@register_backend(\"openai\")</code> \ub370\ucf54\ub808\uc774\ud130\ub97c \ud1b5\ud574 registry\uc5d0 \uc774\ub984\uc744 \ub4f1\ub85d\ud569\ub2c8\ub2e4.</li> <li> <p>Runner CLI\uc5d0\uc11c <code>--backend openai</code> \ub85c \uc120\ud0dd\ud560 \uc218 \uc788\uac8c \ub429\ub2c8\ub2e4.</p> </li> <li> <p>\ucd08\uae30\ud654 &amp; \ud074\ub77c\uc774\uc5b8\ud2b8 \uc0dd\uc131</p> </li> </ul> <p><code>python   def _get_client(self) -&gt; AsyncOpenAI:       api_key = self.backend_options.get(\"api_key\") or os.getenv(\"OPENAI_API_KEY\")       if not api_key:           raise BackendError(\"OPENAI_API_KEY is not set\", error_type=\"auth\", retryable=False)       base_url = self.backend_options.get(\"base_url\") or os.getenv(\"OPENAI_BASE_URL\")       self._client = AsyncOpenAI(api_key=api_key, base_url=base_url)       return self._client</code></p> <ul> <li>\ud658\uacbd \ubcc0\uc218 \ub610\ub294 backend \uc635\uc158\uc73c\ub85c API \ud0a4/\uc5d4\ub4dc\ud3ec\uc778\ud2b8\ub97c \uc8fc\uc785</li> <li> <p>\ud0a4\uac00 \uc5c6\uc73c\uba74 <code>BackendError(error_type=\"auth\")</code> \ub85c \uba85\ud655\ud788 \uc2e4\ud328</p> </li> <li> <p>\uc694\uccad \uc804\uc1a1</p> </li> </ul> <p>```python   async def send(self, request: RunRequest) -&gt; ChatResponse:       client = self._get_client()       model = request.run_config.model or self.backend_options.get(\"model\")       if not model:           raise BackendError(\"RunConfig.model is required for OpenAI backend\", error_type=\"config\", retryable=False)</p> <pre><code>  params = {\n      \"model\": model,\n      \"messages\": _build_messages(request.messages),\n  }\n  params.update(self.backend_options.get(\"request_defaults\", {}))\n  params.update(request.run_config.parameters)\n\n  try:\n      resp = await client.chat.completions.create(**params)\n  except RateLimitError as exc:\n      raise BackendError(str(exc), error_type=\"rate_limit\", status_code=429, retryable=True)\n  except (APIConnectionError, APIError) as exc:\n      retryable = getattr(exc, \"status_code\", 500) &gt;= 500\n      raise BackendError(str(exc), error_type=\"api_error\", status_code=getattr(exc, \"status_code\", None), retryable=retryable)\n  except (BadRequestError, AuthenticationError) as exc:\n      raise BackendError(str(exc), error_type=\"request_error\", status_code=getattr(exc, \"status_code\", None), retryable=False)\n  except Exception as exc:\n      raise BackendError(str(exc), error_type=\"unknown\", retryable=False)\n\n  choice = resp.choices[0]\n  text = choice.message.content or \"\"\n  usage = None\n  if resp.usage is not None:\n      usage = TokenUsage(\n          input_tokens=resp.usage.prompt_tokens,\n          output_tokens=resp.usage.completion_tokens,\n          total_tokens=resp.usage.total_tokens,\n      )\n\n  return ChatResponse(\n      text=text,\n      raw=resp.model_dump(mode=\"python\"),\n      usage=usage,\n      finish_reason=choice.finish_reason,\n      status_code=200,\n  )\n</code></pre> <p>```</p> <ul> <li>RunConfig.parameters + backend_options.request_defaults \ub97c \ud569\uccd0 OpenAI Chat Completions \ud638\ucd9c</li> <li>\ub2e4\uc591\ud55c \uc608\uc678\ub97c <code>BackendError</code> \ub85c \ub798\ud551\ud574 Runner\uac00 \ucc98\ub9ac\ud558\uae30 \uc27d\uac8c \ub9cc\ub4e6</li> <li>\uc751\ub2f5\uc744 <code>ChatResponse</code> \ub85c \ubcc0\ud658\ud574 Runner\ub85c \ubc18\ud658</li> </ul>"},{"location":"usage/extending-backends/#3-backend","title":"3. \uc0c8 Backend \ucd94\uac00 \uc808\ucc28","text":"<p>\uc0c8 Backend\ub97c \ucd94\uac00\ud560 \ub54c\uc758 \uacf5\ud1b5 \ud328\ud134\uc740 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4.</p> <ol> <li><code>ChatBackend</code> \uc778\ud130\ud398\uc774\uc2a4\ub97c \uad6c\ud604\ud558\ub294 \ud074\ub798\uc2a4 \uc791\uc131</li> <li><code>@register_backend(\"\uc774\ub984\")</code> \ub370\ucf54\ub808\uc774\ud130\ub85c registry \ub4f1\ub85d</li> <li>Backend \uc635\uc158/\ud658\uacbd \ubcc0\uc218 \uc124\uacc4 (<code>api_key</code>, <code>base_url</code>, <code>request_defaults</code> \ub4f1)</li> </ol>"},{"location":"usage/extending-backends/#31-dummy-backend","title":"3.1 \uc608: Dummy Backend (\uace0\uc815 \uc751\ub2f5)","text":"<p>\ud14c\uc2a4\ud2b8/CI \uc6a9\ub3c4\ub85c \uc678\ubd80 API\ub97c \ud638\ucd9c\ud558\uc9c0 \uc54a\uace0 \uace0\uc815 \uc751\ub2f5\ub9cc \ubc18\ud658\ud558\ub294 Backend\ub97c \ub9cc\ub4e4 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p> <p>\uac1c\ub150\uc801 \uc608:</p> <pre><code>@register_backend(\"dummy\")\nclass DummyBackend(ChatBackend):\n    async def send(self, request: RunRequest) -&gt; ChatResponse:\n        text = \"This is a dummy response for sample=\" + request.sample.id\n        return ChatResponse(text=text)\n</code></pre> <p>\uc774\ub807\uac8c \ud558\uba74 Runner CLI\uc5d0\uc11c:</p> <pre><code>python -m lm_eval_so.runner.cli \\\n  --dataset path/to/dataset \\\n  --backend dummy \\\n  --output-dir runs/dummy\n</code></pre> <p>\ud615\ud0dc\ub85c \ube60\ub978 \uc2a4\ubaa8\ud06c \ud14c\uc2a4\ud2b8\ub97c \uad6c\ud604\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p>"},{"location":"usage/extending-backends/#32-http-generic-backend","title":"3.2 \uc608: HTTP Generic Backend","text":"<p>\uc5b4\ub5a4 REST API\uc5d0 <code>POST /chat</code> \ud615\ud0dc\ub85c \uc694\uccad\ud558\uace0 \uc2f6\uc740 \uacbd\uc6b0, \ub2e4\uc74c\uacfc \uac19\uc740 \ud328\ud134\uc744 \uc0ac\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p> <ul> <li>backend \uc635\uc158\uc5d0:</li> <li><code>base_url</code>: API \ubca0\uc774\uc2a4 URL</li> <li><code>headers</code>: \uc778\uc99d/\ucee4\uc2a4\ud140 \ud5e4\ub354</li> <li><code>request_template</code>: body \uc2a4\ud0a4\ub9c8 (messages + run_config\ub97c \uc5b4\ub5bb\uac8c \ub123\uc744\uc9c0)</li> </ul> <p>Backend \ub0b4\ubd80\uc5d0\uc11c\ub294:</p> <ul> <li><code>httpx.AsyncClient</code> \ub4f1\uc73c\ub85c HTTP \uc694\uccad \uc804\uc1a1</li> <li>\uc751\ub2f5 JSON\uc5d0\uc11c \ud14d\uc2a4\ud2b8/\ud1a0\ud070 \uc815\ubcf4\ub9cc \uace8\ub77c <code>ChatResponse</code> \ub85c \ubcc0\ud658</li> </ul> <p>\uc774\ub54c\ub3c4, \uc624\ub958\ub294 \ubc18\ub4dc\uc2dc <code>BackendError</code> \ub85c \ub798\ud551\ud574 Runner\uc5d0 \uc804\ub2ec\ud574\uc57c \ud569\ub2c8\ub2e4.</p>"},{"location":"usage/extending-backends/#4-timeout-retry-rate-limit","title":"4. timeout / retry / rate-limit / \ub85c\uae45 \ubca0\uc2a4\ud2b8 \ud504\ub799\ud2f0\uc2a4","text":""},{"location":"usage/extending-backends/#41-timeout","title":"4.1 timeout","text":"<ul> <li>\uc5b4\ub514\uc11c timeout\uc744 \uac70\ub294\uc9c0\uac00 \uc911\uc694\ud569\ub2c8\ub2e4.</li> <li>Runner \ub808\ubca8: <code>asyncio.wait_for(backend.send(...), timeout=options.timeout_seconds)</code></li> <li>Backend \ub808\ubca8: HTTP \ud074\ub77c\uc774\uc5b8\ud2b8 \ud0c0\uc784\uc544\uc6c3 \uc124\uc815</li> <li>\uad8c\uc7a5 \ud328\ud134</li> <li>Backend\uc5d0\uc11c\ub294 \ud074\ub77c\uc774\uc5b8\ud2b8 \uae30\ubcf8 timeout\ub9cc \uc124\uc815</li> <li>Runner\uc5d0\uc11c per-sample timeout\uc744 \uc77c\uad00\ub418\uac8c \uad00\ub9ac (\uc774\ubbf8 \uad6c\ud604\ub418\uc5b4 \uc788\uc74c)</li> </ul>"},{"location":"usage/extending-backends/#42-retry","title":"4.2 retry","text":"<ul> <li>\uc7ac\uc2dc\ub3c4 \ub85c\uc9c1\uc740 Runner \ucabd\uc5d0 \ub450\ub294 \uac83\uc774 \uc77c\ubc18\uc801\uc785\ub2c8\ub2e4.</li> <li>Backend\ub294 <code>BackendError(retryable=True/False)</code> \ub85c\ub9cc \uc758\ub3c4 \uc804\ub2ec</li> <li>Runner\ub294 <code>max_retries</code>, <code>retry_backoff_factor</code>, <code>retry_backoff_jitter</code> \ub97c \uc0ac\uc6a9\ud574 backoff \uc804\ub7b5 \uc801\uc6a9</li> <li>Backend \uad6c\ud604\uc5d0\uc11c\ub294:</li> <li>429, 5xx, \ub124\ud2b8\uc6cc\ud06c \uc5d0\ub7ec \ub4f1 \uc7ac\uc2dc\ub3c4 \uac00\ub2a5\ud55c \uc624\ub958\ub294 <code>retryable=True</code> \ub85c \ud45c\uc2dc</li> <li>\uc778\uc99d/\uad6c\uc131 \uc624\ub958(401/403/400 \ub4f1)\ub294 <code>retryable=False</code></li> </ul>"},{"location":"usage/extending-backends/#43-rate-limit","title":"4.3 rate-limit","text":"<ul> <li>Runner\uc5d0\ub294 <code>_RateLimiter</code> \uac00 \uc788\uc5b4 \ucd08\ub2f9 \uc694\uccad \uc218\ub97c \uc81c\uc5b4\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</li> <li>Backend\ub294 rate-limit\uc744 \ubaa8\ub974\uba74 \ucd5c\ub300\ud55c \ub2e8\uc21c\ud788 API \uc5d0\ub7ec\ub9cc \uc804\ub2ec\ud558\uace0,</li> <li>Runner\uc758 <code>rate_limit_per_second</code> \uc635\uc158\uc744 \ud1b5\ud574 \uc804\uccb4 \uc2e4\ud589 \uc18d\ub3c4\ub97c \uc81c\uc5b4\ud558\ub294 \uad6c\uc870\ub97c \ucd94\ucc9c\ud569\ub2c8\ub2e4.</li> </ul>"},{"location":"usage/extending-backends/#44-observability","title":"4.4 \ub85c\uae45 / Observability","text":"<p>Backend/Runner \uc124\uacc4 \uc2dc \ubc18\ub4dc\uc2dc \ub0a8\uaca8\uc57c \ud560 \uc815\ubcf4:</p> <ul> <li>\uc694\uccad/\uc751\ub2f5 \uc694\uc57d (\uc804\uccb4 raw payload\uac00 \uc544\ub2c8\ub77c\ub3c4, \ud14d\uc2a4\ud2b8/\ud1a0\ud070/\uc0c1\ud0dc\ucf54\ub4dc \uc815\ub3c4)</li> <li>latency, \uc2dc\ub3c4 \ud69f\uc218, trace_id</li> <li>error_type / status_code / retryable \uc5ec\ubd80</li> </ul> <p>\uad8c\uc7a5 \ud328\ud134:</p> <ul> <li>Runner\uc758 logger (<code>lm_eval_so.runner</code>) \ub97c \uc0ac\uc6a9\ud574 structured logging \uc9c0\ud5a5</li> <li><code>trace_prefix</code>/<code>trace_id</code> \ub97c \uc774\uc6a9\ud574 \ud55c execution \ud750\ub984\uc744 \ucd94\uc801 \uac00\ub2a5\ud558\uac8c \ub9cc\ub4e4\uae30</li> </ul>"},{"location":"usage/extending-backends/#5","title":"5. \uc694\uc57d","text":"<ul> <li>Backend\ub294 \uc678\ubd80 \uc2dc\uc2a4\ud15c\uc744 \uac10\uc2f8\ub294 \uc5b4\ub311\ud130\uc774\uba70, Runner\ub294 \uc774\ub97c \ud1b5\ud574 <code>(Dataset \u00d7 Backend \u00d7 RunConfig) \u2192 RunResult[]</code> \ub97c \uc2e4\ud589\ud569\ub2c8\ub2e4.</li> <li>\uc0c8 Backend\ub97c \ucd94\uac00\ud558\ub824\uba74:</li> <li><code>ChatBackend</code> \uc778\ud130\ud398\uc774\uc2a4\ub97c \uad6c\ud604\ud558\ub294 \ud074\ub798\uc2a4 \uc791\uc131</li> <li><code>@register_backend(\"\uc774\ub984\")</code> \ub85c registry\uc5d0 \ub4f1\ub85d</li> <li>\ud544\uc694\uc2dc backend \uc635\uc158/\ud658\uacbd \ubcc0\uc218 \uc124\uacc4 (<code>api_key</code>, <code>base_url</code>, <code>request_defaults</code> \ub4f1)</li> <li>timeout/retry/rate-limit\uc740 Runner\uc640 Backend\uc758 \uc5ed\ud560\uc744 \ubd84\ub9ac\ud574\uc11c \uc124\uacc4\ud558\uace0,</li> <li>Backend\ub294 \uc624\ub958\ub97c <code>BackendError(error_type, retryable, status_code, details)</code> \ub85c\ub9cc \ud45c\ud604</li> <li>Runner\uac00 \ub3d9\uc2dc\uc131/\uc7ac\uc2dc\ub3c4/\uc18d\ub3c4 \uc81c\uc5b4\ub97c \ub2f4\ub2f9\ud558\ub3c4\ub85d \ud558\ub294 \uac83\uc774 \ubc14\ub78c\uc9c1\ud569\ub2c8\ub2e4.</li> <li>\ub85c\uae45/trace\ub97c \ucda9\ubd84\ud788 \ub0a8\uaca8\ub450\uba74, \ub098\uc911\uc5d0 \uc810\uc218\uac00 \ub0ae\uc740 \uad6c\uac04\uc744 \ub514\ubc84\uae45\ud558\uac70\ub098   \uc0c8\ub85c\uc6b4 Backend\ub97c \ubd99\uc77c \ub54c\ub3c4 \ud6e8\uc52c \uc218\uc6d4\ud574\uc9d1\ub2c8\ub2e4.</li> </ul>"},{"location":"usage/extending-metrics/","title":"Metric \ud655\uc7a5 \uac00\uc774\ub4dc (\uc0c8 Metric \ucd94\uac00\ud558\uae30)","text":"<p>\uc774 \ubb38\uc11c\ub294 <code>lm-eval-so</code>\uc758 Evaluator Metric \ud50c\ub7ec\uadf8\uc778\uc744 \ud655\uc7a5\ud558\ub294 \ubc29\ubc95\uc744 \uc815\ub9ac\ud569\ub2c8\ub2e4.</p> <ul> <li>Metric \uc778\ud130\ud398\uc774\uc2a4 \uac1c\ub150</li> <li>\uae30\ubcf8 Metric(<code>exact_match</code>, <code>keyword_coverage</code>, <code>llm_judge</code>) \uad6c\uc870</li> <li>\uc0c8 Metric \uad6c\ud604 + registry \ub4f1\ub85d \ubc29\ubc95</li> <li>G-Eval / LLM-Judge \uacc4\uc5f4 Metric \uc124\uacc4 \uc2dc \uc8fc\uc758\uc810</li> </ul> <p>\uc774 \ubb38\uc11c\ub294 \uac1c\ub150/\ud328\ud134 \uc704\uc8fc \uac00\uc774\ub4dc\uc774\uba70, \uc2e4\uc81c \uad6c\ud604\uccb4 \ucf54\ub4dc\ub294 <code>src/lm_eval_so/evaluator/metrics/</code> \uc640 <code>src/lm_eval_so/evaluator/registry.py</code> \ub4f1\uc744 \ucc38\uace0\ud558\uc138\uc694.</p>"},{"location":"usage/extending-metrics/#1-metric","title":"1. Metric \uc778\ud130\ud398\uc774\uc2a4 \uac1c\ub150","text":"<p>Evaluator\ub294 Metric \ud50c\ub7ec\uadf8\uc778\uc744 \ud1b5\ud574 \uc810\uc218\ub97c \uacc4\uc0b0\ud569\ub2c8\ub2e4.</p> <p>\uac1c\ub150\uc801\uc73c\ub85c Metric\uc740 \ub2e4\uc74c \uc778\ud130\ud398\uc774\uc2a4\ub97c \uac00\uc9d1\ub2c8\ub2e4.</p> <ul> <li>\uc785\ub825:</li> <li><code>TestSampleRecord</code> (dataset\uc5d0\uc11c \uc628 \ud55c \uc0d8\ud50c)</li> <li><code>RunRecord</code> (Runner\uac00 \uc0dd\uc131\ud55c \ud55c \ubc88\uc758 \uc2e4\ud589 \uacb0\uacfc)</li> <li>\ucd9c\ub825:</li> <li><code>EvalScore</code> (metric \uc774\ub984, \uac12, \uc138\ubd80 \uc815\ubcf4\uac00 \ub4e4\uc5b4 \uc788\ub294 \ub808\ucf54\ub4dc)</li> </ul> <p>Pseudo-code\ub85c \ubcf4\uba74:</p> <pre><code>class Metric(Protocol):\n    name: str\n    parameters: dict\n    requires_reference: bool\n\n    def score(self, sample: TestSampleRecord, run: RunRecord) -&gt; EvalScore:\n        ...\n\n    def build_llm_judge_details(self, scores: Iterable[EvalScore]) -&gt; list[LLMJudgeDetail]:\n        ...  # \ub300\ubd80\ubd84\uc758 Metric\uc5d0\uc11c\ub294 \ube48 \ub9ac\uc2a4\ud2b8\ub97c \ubc18\ud658\n</code></pre> <p>\uc2e4\uc81c \uad6c\ud604\uc5d0\uc11c\ub294 \uacf5\ud1b5 \ubca0\uc774\uc2a4 \ud074\ub798\uc2a4(<code>Metric</code>)\uac00 \uc788\uc5b4, \ub2e4\uc74c\uacfc \uac19\uc740 \ub3c4\uc6c0 \uba54\uc11c\ub4dc\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4.</p> <ul> <li><code>self.make_score(sample, value: float, detail: dict | None)</code></li> <li>metric \uc774\ub984/\uac12/\uc138\ubd80\uc815\ubcf4\ub97c \ud3ec\ud568\ud558\ub294 <code>EvalScore</code>\ub97c \uc0dd\uc131</li> </ul> <p><code>requires_reference: bool</code>\uc740 \ucc38\uc870 \uc815\ub2f5(expected)\uc774 \ud544\uc694 \uc5ec\ubd80\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.</p> <ul> <li>\uc608: exact_match \u2192 <code>requires_reference = True</code></li> <li>\uc608: keyword_coverage \u2192 <code>requires_reference = False</code></li> </ul>"},{"location":"usage/extending-metrics/#2-metric","title":"2. \uae30\ubcf8 Metric \uc608\uc2dc \uc0b4\ud3b4\ubcf4\uae30","text":""},{"location":"usage/extending-metrics/#21-exactmatchmetric-exact_match","title":"2.1 ExactMatchMetric (<code>exact_match</code>)","text":"<p>\uc5ed\ud560:</p> <ul> <li><code>sample.expected</code>\uc640 \ubaa8\ub378 \uc751\ub2f5(<code>run.response_text</code>)\uc774</li> <li>\uacf5\ubc31 \uc815\uaddc\ud654, \ub300\uc18c\ubb38\uc790 \uc635\uc158\uc5d0 \ub530\ub77c \uc644\uc804\ud788 \ub3d9\uc77c\ud55c\uc9c0 \ud3c9\uac00</li> </ul> <p>\ud575\uc2ec \ud3ec\uc778\ud2b8:</p> <ul> <li>\ud30c\ub77c\ubbf8\ud130</li> <li><code>normalize_whitespace: bool</code> (\uae30\ubcf8 True)</li> <li><code>case_sensitive: bool</code> (\uae30\ubcf8 False)</li> <li>\ub85c\uc9c1</li> <li>expected \ub610\ub294 answer\uac00 \uc5c6\uc73c\uba74 <code>skipped</code> \ud50c\ub798\uadf8\ub97c detail\uc5d0 \uae30\ub85d</li> <li>\ub450 \ud14d\uc2a4\ud2b8\ub97c normalize \ud6c4 \uc644\uc804 \uc77c\uce58\ud558\uba74 <code>value=1.0</code>, \uc544\ub2c8\uba74 <code>0.0</code></li> <li>detail \uc608\uc2dc</li> <li><code>{ \"expected\": \"...\", \"answer\": \"...\", \"match\": true/false }</code></li> </ul>"},{"location":"usage/extending-metrics/#22-keywordcoveragemetric-keyword_coverage","title":"2.2 KeywordCoverageMetric (<code>keyword_coverage</code>)","text":"<p>\uc5ed\ud560:</p> <ul> <li>\ubbf8\ub9ac \uc124\uc815\ud55c \ud0a4\uc6cc\ub4dc \ub9ac\uc2a4\ud2b8\uac00 \uc751\ub2f5 \ud14d\uc2a4\ud2b8\uc5d0 \uc5bc\ub9c8\ub098 \ud3ec\ud568\ub410\ub294\uc9c0 coverage(\ud3ec\ud568 \ube44\uc728) \ud3c9\uac00</li> </ul> <p>\ud575\uc2ec \ud3ec\uc778\ud2b8:</p> <ul> <li>\ud30c\ub77c\ubbf8\ud130</li> <li><code>keywords: list[str]</code> (\ud544\uc218)</li> <li><code>case_sensitive: bool</code> (\uae30\ubcf8 False)</li> <li>\ub85c\uc9c1</li> <li>\uc751\ub2f5 \ud14d\uc2a4\ud2b8\ub97c \uc801\uc808\ud788 lower-case \ucc98\ub9ac</li> <li>\uac01 \ud0a4\uc6cc\ub4dc\uac00 \ud3ec\ud568\ub418\uba74 <code>matched += 1</code></li> <li><code>value = matched / total_keywords</code></li> <li>detail \uc608\uc2dc</li> <li><code>{ \"matched\": 2, \"total_keywords\": 3 }</code></li> </ul>"},{"location":"usage/extending-metrics/#23-llmjudgemetric-llm_judge","title":"2.3 LLMJudgeMetric (<code>llm_judge</code>)","text":"<p>\uc5ed\ud560:</p> <ul> <li>\uc2e4\uc81c LLM \ud638\ucd9c\uc740 \ud558\uc9c0 \uc54a\uace0, \uc774\ubbf8 Runner/\uc678\ubd80 \ud30c\uc774\ud504\ub77c\uc778\uc774 <code>RunRecord.raw</code> \uc548\uc5d0 \uae30\ub85d\ud574 \ub454 LLM Judge \uc810\uc218\ub97c \uc18c\ube44</li> <li>\uc608: <code>run.raw[\"llm_judge\"][\"score\"]</code> \uc5d0 \uc800\uc7a5\ub41c 1~5\uc810 \uc810\uc218\ub97c \uc77d\uc5b4\uc11c 0~1 \uc0ac\uc774\ub85c \uc815\uaddc\ud654</li> </ul> <p>\ud575\uc2ec \ud3ec\uc778\ud2b8:</p> <ul> <li>\ud30c\ub77c\ubbf8\ud130</li> <li><code>prompt_id: str</code></li> <li><code>prompt_version: str</code></li> <li><code>criteria: list[str]</code> (\uc608: [\"correctness\", \"fluency\"])</li> <li><code>max_score: float</code> (\uae30\ubcf8 5.0)</li> <li><code>score_key: str</code> (\uae30\ubcf8 <code>\"llm_judge.score\"</code>)</li> <li>\ub85c\uc9c1</li> <li><code>score_key</code> \uacbd\ub85c\ub97c \ub530\ub77c <code>run.raw</code>\uc5d0\uc11c \uac12 \uc870\ud68c</li> <li>\uc5c6\uc73c\uba74 <code>skipped</code> \ucc98\ub9ac</li> <li>\uc22b\uc790\ub85c \uce90\uc2a4\ud305 \ud6c4 <code>value = numeric / max_score</code></li> <li><code>build_llm_judge_details(...)</code> \uad6c\ud604</li> <li>\ud55c \ubc88\uc758 metric \uc2e4\ud589 \uc804\uccb4\uc5d0 \ub300\ud55c LLM-Judge \uc694\uc57d \ub808\ucf54\ub4dc(<code>LLMJudgeDetail</code>) \uc0dd\uc131</li> <li>prompt_id/version, language, criteria, sample_count, sample_ids \ub4f1\uc744 \ud3ec\ud568</li> </ul>"},{"location":"usage/extending-metrics/#3-metric","title":"3. \uc0c8 Metric \uad6c\ud604 \uc808\ucc28","text":"<p>\uc0c8 Metric\uc744 \ucd94\uac00\ud558\ub824\uba74 3\ub2e8\uacc4\uc785\ub2c8\ub2e4.</p> <ol> <li>Metric \ud074\ub798\uc2a4 \uad6c\ud604 (<code>metrics/</code> \uc544\ub798 \uc0c8 \ud30c\uc77c \ub610\ub294 \uae30\uc874 \ud30c\uc77c \ub0b4 \ud074\ub798\uc2a4 \ucd94\uac00)</li> <li>Metric registry\uc5d0 \ub4f1\ub85d (<code>register_default_metrics</code> \ub610\ub294 \ubcc4\ub3c4 registry \ud638\ucd9c)</li> <li>Evaluator \uc124\uc815 \ud30c\uc77c(config)\uc5d0\uc11c metric type/name/parameters \uc124\uc815</li> </ol>"},{"location":"usage/extending-metrics/#31-metric","title":"3.1 Metric \ud074\ub798\uc2a4 \uad6c\ud604","text":"<p>\uc608\ub97c \ub4e4\uc5b4, \uc751\ub2f5 \uae38\uc774 \uae30\ubc18 Metric(\ub108\ubb34 \uc9e7\uac70\ub098 \uae34 \uc751\ub2f5 penalize)\uc744 \ub9cc\ub4e0\ub2e4\uace0 \uac00\uc815\ud574 \ubd05\uc2dc\ub2e4.</p> <p>\uac1c\ub150\uc801 \uad6c\uc870:</p> <pre><code>from .base import Metric\nfrom ..domain import EvalScore, RunRecord, TestSampleRecord\n\n\nclass LengthPenaltyMetric(Metric):\n    \"\"\"\uc751\ub2f5 \uae38\uc774\uac00 \ub108\ubb34 \uc9e7\uac70\ub098 \uae38 \uacbd\uc6b0 \ud328\ub110\ud2f0\ub97c \uc8fc\ub294 \uc608\uc81c metric.\"\"\"\n\n    requires_reference: bool = False\n\n    def __init__(self, *, name: str, parameters: Mapping[str, Any] | None = None) -&gt; None:\n        super().__init__(name=name, parameters=parameters)\n        p = self.parameters\n        self._min_len = int(p.get(\"min_len\", 1))\n        self._max_len = int(p.get(\"max_len\", 512))\n\n    def score(self, sample: TestSampleRecord, run: RunRecord) -&gt; EvalScore:\n        text = run.response_text or \"\"\n        length = len(text)\n\n        if length == 0:\n            value = 0.0\n            detail = {\"length\": length, \"reason\": \"empty_response\"}\n        elif length &lt; self._min_len:\n            value = 0.3  # \ub108\ubb34 \uc9e7\uc73c\uba74 \ud328\ub110\ud2f0\n            detail = {\"length\": length, \"reason\": \"too_short\"}\n        elif length &gt; self._max_len:\n            value = 0.5  # \ub108\ubb34 \uae38\uc5b4\ub3c4 \ud328\ub110\ud2f0\n            detail = {\"length\": length, \"reason\": \"too_long\"}\n        else:\n            value = 1.0\n            detail = {\"length\": length, \"reason\": \"ok\"}\n\n        return self.make_score(sample, value=value, detail=detail)\n</code></pre> <p>\uc704 \uc608\uc2dc\ub294 \uac1c\ub150\uc801\uc778 \ud328\ud134\ub9cc \ubcf4\uc5ec\uc8fc\uba70, \uc2e4\uc81c \uac12(0.3/0.5 \ub4f1)\uc740 \ud504\ub85c\uc81d\ud2b8 \uc694\uad6c\uc5d0 \ub9de\uac8c \uc124\uacc4\ud574\uc57c \ud569\ub2c8\ub2e4.</p>"},{"location":"usage/extending-metrics/#32-metric-registry","title":"3.2 Metric Registry\uc5d0 \ub4f1\ub85d","text":"<p>Evaluator\ub294 \ub0b4\ubd80\uc801\uc73c\ub85c MetricRegistry\ub97c \uc0ac\uc6a9\ud574 <code>type</code> \uc774\ub984\uc73c\ub85c Metric\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4.</p> <p>\uae30\ubcf8 \ub4f1\ub85d \ud568\uc218\ub294 \ub300\ub7b5 \ub2e4\uc74c\uacfc \uac19\uc740 \ud615\ud0dc\uc785\ub2c8\ub2e4.</p> <pre><code>from .exact_match import ExactMatchMetric\nfrom .keyword import KeywordCoverageMetric\nfrom .llm_judge import LLMJudgeMetric\n\n\ndef register_default_metrics(registry: MetricRegistry) -&gt; None:\n    def _safe_register(name: str, factory):\n        ...\n\n    _safe_register(\"exact_match\", lambda cfg: ExactMatchMetric(**cfg))\n    _safe_register(\"keyword_coverage\", lambda cfg: KeywordCoverageMetric(**cfg))\n    _safe_register(\"llm_judge\", lambda cfg: LLMJudgeMetric(**cfg))\n</code></pre> <p>\uc0c8 Metric\uc744 \ub4f1\ub85d\ud558\ub824\uba74, \uc5ec\uae30\uc5d0 \ud55c \uc904\uc744 \ucd94\uac00\ud558\uba74 \ub429\ub2c8\ub2e4.</p> <pre><code>from .length_penalty import LengthPenaltyMetric\n\n    _safe_register(\"length_penalty\", lambda cfg: LengthPenaltyMetric(**cfg))\n</code></pre> <ul> <li><code>\"length_penalty\"</code> \ubb38\uc790\uc5f4\uc774 Evaluator \uc124\uc815 \ud30c\uc77c\uc758 <code>type</code> \ud544\ub4dc\uc5d0\uc11c \uc0ac\uc6a9\ub418\ub294 \uc774\ub984\uc774 \ub429\ub2c8\ub2e4.</li> </ul>"},{"location":"usage/extending-metrics/#33-evaluator-config","title":"3.3 Evaluator \uc124\uc815(config)\uc5d0\uc11c \uc0ac\uc6a9\ud558\uae30","text":"<p>\ub4f1\ub85d\uc744 \ub9c8\uce5c \ub4a4\uc5d0\ub294 Evaluator \uc124\uc815 \ud30c\uc77c(YAML/JSON)\uc5d0\uc11c \uc0c8 Metric\uc744 \ucc38\uc870\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p> <pre><code>metrics:\n  - type: length_penalty\n    name: length_penalty\n    parameters:\n      min_len: 10\n      max_len: 256\n</code></pre> <ul> <li><code>type</code>: registry\uc5d0 \ub4f1\ub85d\ud55c \uc774\ub984</li> <li><code>name</code>: \ub9ac\ud3ec\ud2b8\uc5d0 \ud45c\uc2dc\ub420 metric \uc774\ub984 (\uc0dd\ub7b5\ud558\uba74 type\uc73c\ub85c \ub300\uccb4\ub418\ub294 \ud615\ud0dc\ub97c \uc0ac\uc6a9\ud558\ub294 \uac83\uc774 \uc77c\ubc18\uc801)</li> <li><code>parameters</code>: Metric \uc0dd\uc131\uc790\uc5d0 \uc804\ub2ec\ud560 \ud30c\ub77c\ubbf8\ud130</li> </ul> <p>\uc774\ub807\uac8c \uc124\uc815\ud558\uba74 Evaluator\ub294 \ub2e4\ub978 metric\ub4e4\uacfc \ub3d9\uc77c\ud55c \ubc29\uc2dd\uc73c\ub85c <code>LengthPenaltyMetric</code>\uc744 \uc2e4\ud589\ud558\uac8c \ub429\ub2c8\ub2e4.</p>"},{"location":"usage/extending-metrics/#4-g-eval-llm-judge-metric","title":"4. G-Eval / LLM-Judge Metric \uc124\uacc4 \uc2dc \uc8fc\uc758\uc810","text":"<p>LLM \uae30\ubc18 \ud3c9\uac00(G-Eval, LLM-as-a-Judge)\ub294 \ube44\uc6a9/\uc77c\uad00\uc131/\ubc84\uc804 \uad00\ub9ac\uac00 \uc911\uc694\ud569\ub2c8\ub2e4. \uc124\uacc4 \uc2dc \ub2e4\uc74c\uc744 \uad8c\uc7a5\ud569\ub2c8\ub2e4.</p>"},{"location":"usage/extending-metrics/#41-runner-vs-evaluator","title":"4.1 Runner vs Evaluator \uc5ed\ud560 \ubd84\ub9ac","text":"<p>\ud604 \uc124\uacc4\uc5d0\uc11c\ub294:</p> <ul> <li>Runner/\uc678\ubd80 \ud30c\uc774\ud504\ub77c\uc778</li> <li>\uc2e4\uc81c LLM Judge API\ub97c \ud638\ucd9c\ud558\uace0, \uc6d0\ubcf8 \ud3c9\uac00 \uacb0\uacfc\ub97c <code>RunRecord.raw</code> \ub4f1\uc5d0 \uc800\uc7a5</li> <li>Evaluator\uc758 <code>llm_judge</code> Metric</li> <li>\uc774\ubbf8 \uacc4\uc0b0\ub41c \uc810\uc218\ub97c \uc77d\uc5b4\uc640 \uc815\uaddc\ud654/\uc9d1\uacc4\ub9cc \uc218\ud589</li> </ul> <p>\uc774\ub807\uac8c \uc5ed\ud560\uc744 \ubd84\ub9ac\ud558\uba74 \ub2e4\uc74c \uc7a5\uc810\uc774 \uc788\uc2b5\ub2c8\ub2e4.</p> <ul> <li>Evaluator \uc2e4\ud589 \uc2dc \ucd94\uac00 API \ube44\uc6a9\uc774 \ub4e4\uc9c0 \uc54a\uc74c</li> <li>\uac19\uc740 RunResult\uc5d0 \ub300\ud574 \uc5ec\ub7ec \ubc88 \uc7ac\ud3c9\uac00/\ub9ac\ud3ec\ud2b8\ub97c \ub9cc\ub4e4 \uc218 \uc788\uc74c</li> <li>LLM Judge \ud504\ub86c\ud504\ud2b8/\ubaa8\ub378\uc774 \ubc14\ub00c\ub354\ub77c\ub3c4 Runner \ud30c\uc774\ud504\ub77c\uc778\ub9cc \uad50\uccb4\ud558\uba74 \ub428</li> </ul>"},{"location":"usage/extending-metrics/#42-prompt_id-version-criteria","title":"4.2 prompt_id / version / criteria \uad00\ub9ac","text":"<p>LLM Judge Metric \ud30c\ub77c\ubbf8\ud130\uc5d0\ub294 \ucd5c\uc18c \ub2e4\uc74c \ud56d\ubaa9\uc744 \uba85\uc2dc\uc801\uc73c\ub85c \ub123\ub294 \uac83\uc744 \uad8c\uc7a5\ud569\ub2c8\ub2e4.</p> <ul> <li><code>prompt_id</code>: \ud3c9\uac00 \ud504\ub86c\ud504\ud2b8/\ud15c\ud50c\ub9bf\uc744 \uc2dd\ubcc4\ud558\ub294 ID</li> <li><code>prompt_version</code>: \ud504\ub86c\ud504\ud2b8 \ubc84\uc804 (\uc608: <code>v1</code>, <code>2025-03-01</code>)</li> <li><code>criteria</code>: LLM Judge\uac00 \ud3c9\uac00\ud560 \uae30\uc900 \ub9ac\uc2a4\ud2b8 (\uc608: <code>correctness</code>, <code>faithfulness</code>, <code>style_match</code> \ub4f1)</li> </ul> <p>\uc774\ub97c <code>EvalScore.detail</code> \ub610\ub294 <code>LLMJudgeDetail</code> \uc5d0 \uae30\ub85d\ud574 \ub450\uba74:</p> <ul> <li>\ub098\uc911\uc5d0 \"\uc5b4\ub5a4 \uae30\uc900/\ud504\ub86c\ud504\ud2b8\ub85c \uc810\uc218\ub97c \ub0c8\ub294\uc9c0\"\ub97c \ucd94\uc801 \uac00\ub2a5</li> <li>\ud504\ub86c\ud504\ud2b8\uac00 \uac1c\uc120/\ubcc0\uacbd\ub418\uc5c8\uc744 \ub54c \uc2e4\ud5d8 \ubc84\uc804\uc744 \uba85\ud655\ud788 \uad6c\ubd84 \uac00\ub2a5</li> </ul>"},{"location":"usage/extending-metrics/#43-score_key-max_score","title":"4.3 score_key / max_score \uc124\uacc4","text":"<ul> <li><code>score_key</code>: Runner\uac00 <code>run.raw</code>\uc5d0 \ub123\uc5b4\uc8fc\ub294 \uc810\uc218 \uc704\uce58\ub97c \ubb38\uc790\uc5f4 \uacbd\ub85c\ub85c \uc815\uc758</li> <li>\uc608: <code>\"llm_judge.score\"</code>, <code>\"judge.overall\"</code></li> <li><code>max_score</code>: LLM\uc774 \uc8fc\ub294 \uc6d0\uc810\uc218\uc758 \ucd5c\ub300\uac12</li> <li>\uc608: 1~5 \uc810\uc218\ub77c\uba74 <code>max_score=5.0</code></li> </ul> <p>Metric \uad6c\ud604\uc5d0\uc11c\ub294:</p> <ul> <li><code>raw_value = _get_nested(run.raw, score_key)</code> \ub85c \uac12\uc744 \uc77d\uc5b4\uc624\uace0</li> <li><code>value = raw_value / max_score</code> \ub85c 0~1 \ubc94\uc704\ub85c \uc815\uaddc\ud654</li> </ul> <p>\uc774\ub807\uac8c \ud558\uba74 \ub2e4\ub978 metric\ub4e4\uacfc \ub3d9\uc77c\ud55c \uc2a4\ucf00\uc77c\uc5d0\uc11c \ube44\uad50/\uc9d1\uacc4\ud558\uae30 \ud3b8\ub9ac\ud569\ub2c8\ub2e4.</p>"},{"location":"usage/extending-metrics/#44-sample_rate","title":"4.4 \ube44\uc6a9/\uc0d8\ud50c\ub9c1 \uc804\ub7b5 (sample_rate)","text":"<p>LLM Judge\ub294 \ube44\uc6a9\uc774 \ud06c\uae30 \ub54c\ubb38\uc5d0, Evaluator config\uc5d0\uc11c \uc0d8\ud50c\ub9c1 \ube44\uc728\uc744 \ub450\ub294 \uac83\ub3c4 \uc88b\uc2b5\ub2c8\ub2e4.</p> <p>\uc608\ub97c \ub4e4\uc5b4 MetricConfig\uc5d0 <code>sample_rate: 0.2</code> \ub77c\ub294 \ud544\ub4dc\ub97c \ub450\uace0, \uc804\uccb4 \uc0d8\ud50c \uc911 20%\ub9cc LLM Judge\ub97c \uc801\uc6a9\ud558\ub294 \uc804\ub7b5\uc744 \uc4f8 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p> <p>\uc124\uacc4 \ud301:</p> <ul> <li>\ub300\uaddc\ubaa8 \ud14c\uc2a4\ud2b8\uc5d0\uc11c\ub294 <code>sample_rate &lt; 1.0</code> \uc744 \uae30\ubcf8\uac12\uc73c\ub85c \ub450\uae30</li> <li>\uc5b4\ub5a4 \uc0d8\ud50c subset\uc5d0 LLM Judge\ub97c \uc801\uc6a9\ud588\ub294\uc9c0(\uc608: tag/length \uae30\uc900 stratified sampling) \uba54\ud0c0\ub370\uc774\ud130\uc5d0 \uae30\ub85d</li> </ul>"},{"location":"usage/extending-metrics/#5","title":"5. \uc694\uc57d","text":"<ul> <li>Metric\uc740 <code>sample + run \u2192 EvalScore</code>\ub97c \uacc4\uc0b0\ud558\ub294 \ud50c\ub7ec\uadf8\uc778 \ub2e8\uc704\uc785\ub2c8\ub2e4.</li> <li>\uc0c8 Metric\uc744 \ucd94\uac00\ud558\ub824\uba74:</li> <li><code>Metric</code> \ubca0\uc774\uc2a4 \ud074\ub798\uc2a4\ub97c \uc0c1\uc18d\ud574 <code>score()</code> \uad6c\ud604</li> <li>Metric registry\uc5d0 type \uc774\ub984\uc73c\ub85c \ub4f1\ub85d</li> <li>Evaluator \uc124\uc815 \ud30c\uc77c\uc758 <code>metrics</code> \ub9ac\uc2a4\ud2b8\uc5d0 type/name/parameters \ucd94\uac00</li> <li>G-Eval / LLM-Judge \uacc4\uc5f4 Metric\uc740 Runner\uc640 Evaluator \uc5ed\ud560\uc744 \ubd84\ub9ac\ud558\uace0,</li> <li><code>prompt_id</code> / <code>prompt_version</code> / <code>criteria</code> / <code>score_key</code> / <code>max_score</code> / <code>sample_rate</code>   \ub97c \uba85\uc2dc\uc801\uc73c\ub85c \uad00\ub9ac\ud558\ub294 \uac83\uc774 \uc911\uc694\ud569\ub2c8\ub2e4.</li> </ul> <p>\uc774 \ud328\ud134\uc744 \ub530\ub974\uba74, \uc0c8\ub85c\uc6b4 task-specific metric(\ubc88\uc5ed \ud488\uc9c8/\uc694\uc57d \uc815\ubcf4\ubcf4\uc874/\uc2a4\ud0c0\uc77c \uc77c\uce58\ub3c4 \ub4f1)\uc744 \uc77c\uad00\ub41c \ubc29\uc2dd\uc73c\ub85c \ucd94\uac00\ud558\uace0, \ubcf4\uace0\uc11c \uad6c\uc870\ub3c4 \uc720\uc9c0\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p>"},{"location":"usage/generator/","title":"Generator \uc0ac\uc6a9\ubc95","text":"<p>\uc774 \ubb38\uc11c\ub294 CSV/JSONL \ub4f1 \uc6d0\ucc9c \ub370\uc774\ud130\ub97c canonical <code>TestSample</code> \ub370\uc774\ud130\uc14b\uc73c\ub85c \ubcc0\ud658\ud558\ub294 Generator \ubaa8\ub4c8 \uc0ac\uc6a9 \ubc29\ubc95\uc744 \uc815\ub9ac\ud569\ub2c8\ub2e4.</p>"},{"location":"usage/generator/#1","title":"1. \ud575\uc2ec \uac1c\ub150","text":"<ul> <li>\uc785\ub825: CSV/JSONL \ub4f1\uc758 \ud14c\uc774\ube14/\ub808\ucf54\ub4dc \ub370\uc774\ud130</li> <li>\ucd9c\ub825:</li> <li><code>test.jsonl</code>: canonical <code>TestSample</code> \ub808\ucf54\ub4dc \ub9ac\uc2a4\ud2b8</li> <li><code>metadata.json</code>: dataset_id/name/version, \ud544\ud130/\uc0d8\ud50c\ub9c1 \uc815\ubcf4, \ud0dc\uadf8/\uc5b8\uc5b4 \ud1b5\uacc4</li> <li><code>schema.json</code>: <code>TestSample</code> JSON Schema</li> </ul> <p>Generator\ub294 \ud06c\uac8c \ub2e4\uc74c \ub2e8\uacc4\ub97c \uac70\uce69\ub2c8\ub2e4.</p> <ol> <li>Loader: \ud30c\uc77c(CSV/JSONL)\uc5d0\uc11c row\ub97c \uc77d\uc5b4\uc634</li> <li>Canonicalization: row \u2192 <code>TestSample</code> \uac1d\uccb4\ub85c \ubcc0\ud658</li> <li>Filter/Sample: \uae38\uc774/\uc5b8\uc5b4/\ud0dc\uadf8 \uae30\uc900 \ud544\ud130\ub9c1 \ubc0f \uc0d8\ud50c\ub9c1</li> <li>Writer: JSONL, metadata, schema \ud30c\uc77c\ub85c \ucd9c\ub825</li> </ol>"},{"location":"usage/generator/#2-cli","title":"2. CLI \uac1c\uc694","text":"<p>Generator\ub294 <code>python -m lm_eval_so.generator.cli</code> \ud615\ud0dc\uc758 CLI \uc5d4\ud2b8\ub9ac\ud3ec\uc778\ud2b8\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4.</p> <pre><code>python -m lm_eval_so.generator.cli --help\n</code></pre> <p>\uc8fc\uc694 \uc778\uc790:</p> <ul> <li>\uc785\ub825 \uad00\ub828</li> <li><code>--input</code>: \uc785\ub825 \ud30c\uc77c \uacbd\ub85c (\ud544\uc218, CSV/JSONL)</li> <li><code>--input-format</code>: <code>csv</code> \ub610\ub294 <code>jsonl</code> (\uc0dd\ub7b5 \uc2dc \ud655\uc7a5\uc790\ub85c\ubd80\ud130 \ucd94\ub860)</li> <li>Dataset \uba54\ud0c0\ub370\uc774\ud130</li> <li><code>--dataset-id</code>: dataset \uace0\uc720 ID (\uc608: <code>toy_support_qa</code>)</li> <li><code>--name</code>: dataset \uc774\ub984 (\uc608: <code>\"Toy Support QA\"</code>)</li> <li><code>--version</code>: dataset \ubc84\uc804 (\uc608: <code>v1</code>)</li> <li><code>--source</code>: \uc6d0\ucc9c \ub370\uc774\ud130 \ucd9c\ucc98(\ubb38\uc790\uc5f4 \ub610\ub294 JSON)</li> <li>\uceec\ub7fc \ub9e4\ud551 (CSV \uc804\uc6a9 \uc608\uc2dc)</li> <li><code>--csv-user-col</code>: \uc720\uc800 \uc9c8\ubb38 \uceec\ub7fc\uba85</li> <li><code>--csv-expected-col</code>: \uae30\ub300 \ub2f5\ubcc0 \uceec\ub7fc\uba85</li> <li><code>--csv-system-col</code>: \uc2dc\uc2a4\ud15c \ud504\ub86c\ud504\ud2b8 \uceec\ub7fc\uba85</li> <li><code>--csv-tags-col</code>: \ud0dc\uadf8 \ubb38\uc790\uc5f4 \uceec\ub7fc\uba85 (\uad6c\ubd84\uc790 \uae30\ubcf8 <code>|</code>)</li> <li><code>--csv-language-col</code>: \uc5b8\uc5b4 \ucf54\ub4dc(<code>ko</code>, <code>en</code> \ub4f1) \uceec\ub7fc\uba85</li> <li>\ud544\ud130/\uc0d8\ud50c\ub9c1</li> <li><code>--min-len</code>, <code>--max-len</code>: \uba54\uc2dc\uc9c0 \uae38\uc774 \uae30\uc900 \ud544\ud130</li> <li><code>--sample-size</code>: \uc0d8\ud50c \uac1c\uc218 (0\uc774\uba74 \uc804\uccb4)</li> <li><code>--sample-random</code>: \uc0d8\ud50c\ub9c1 \uc2dc \ub79c\ub364 \uc5ec\ubd80</li> </ul>"},{"location":"usage/generator/#3-jsonl-multi-turn","title":"3. JSONL \uc785\ub825 \ud3ec\ub9f7 (Multi-turn \uc9c0\uc6d0)","text":"<p>CSV \uc678\uc5d0\ub3c4 JSONL(JSON Lines) \ud3ec\ub9f7\uc744 \uc9c0\uc6d0\ud569\ub2c8\ub2e4. \ud2b9\ud788 Multi-turn \ub300\ud654 \ub370\uc774\ud130\uc14b\uc744 \uc0dd\uc131\ud560 \ub54c \uc720\uc6a9\ud569\ub2c8\ub2e4.</p> <p>JSONL \ud30c\uc77c\uc758 \uac01 \ub77c\uc778\uc740 \ub2e4\uc74c \ud544\ub4dc\ub97c \ud3ec\ud568\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4:</p> <ul> <li><code>id</code>: \uc0d8\ud50c ID (\uc0dd\ub7b5 \uc2dc \uc790\ub3d9 \uc0dd\uc131)</li> <li><code>messages</code>: \ub300\ud654 \uba54\uc2dc\uc9c0 \ub9ac\uc2a4\ud2b8 (<code>[{\"role\": \"...\", \"content\": \"...\"}, ...]</code>)</li> <li><code>expected</code>: \uae30\ub300 \ub2f5\ubcc0</li> <li><code>tags</code>: \ud0dc\uadf8 \ub9ac\uc2a4\ud2b8</li> <li><code>lang</code>: \uc5b8\uc5b4 \ucf54\ub4dc</li> <li><code>metadata</code>: \uae30\ud0c0 \uba54\ud0c0\ub370\uc774\ud130</li> </ul>"},{"location":"usage/generator/#multi-turn","title":"Multi-turn \ub370\uc774\ud130 \uc608\uc2dc","text":"<pre><code>{\"id\": \"mt_1\", \"messages\": [{\"role\": \"user\", \"content\": \"A\"}, {\"role\": \"assistant\", \"content\": \"B\"}, {\"role\": \"user\", \"content\": \"C\"}], \"expected\": \"D\", \"tags\": [\"chat\"], \"lang\": \"en\"}\n{\"id\": \"mt_2\", \"messages\": [{\"role\": \"user\", \"content\": \"X\"}], \"expected\": \"Y\", \"tags\": [\"single\"], \"lang\": \"en\"}\n</code></pre> <p>Generator \uc2e4\ud589 \uc2dc <code>--input-format jsonl</code>\uc744 \uc9c0\uc815\ud558\uba74 \ub429\ub2c8\ub2e4.</p> <pre><code>python -m lm_eval_so.generator.cli \\\n  --input my_conversations.jsonl \\\n  --input-format jsonl \\\n  ...\n</code></pre>"},{"location":"usage/generator/#4-quick-start-toy_support_qa","title":"4. Quick Start \uc608\uc81c: toy_support_qa","text":"<p>Quick Start\uc5d0\uc11c\ub294 \uc791\uc740 \uace0\uac1d\uc9c0\uc6d0 QA \uc608\uc81c\ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4.</p> <ul> <li>\uc785\ub825: <code>example/quickstart/data/toy_support_qa.csv</code></li> <li>\uceec\ub7fc: <code>id, system, user, expected, tags, lang</code></li> <li>\ucd9c\ub825 \ub8e8\ud2b8: <code>example/quickstart/dataset/</code></li> </ul> <p>\uc9c1\uc811 \uc2e4\ud589 \uc608\uc2dc:</p> <pre><code>python -m lm_eval_so.generator.cli \\\n  --input example/quickstart/data/toy_support_qa.csv \\\n  --input-format csv \\\n  --output-dir example/quickstart/dataset \\\n  --dataset-id toy_support_qa \\\n  --name \"Toy Support QA\" \\\n  --version v1 \\\n  --csv-user-col user \\\n  --csv-expected-col expected \\\n  --csv-system-col system \\\n  --csv-tags-col tags \\\n  --csv-language-col lang \\\n  --sample-size 3 \\\n  --sample-random\n</code></pre> <p>\uc2e4\ud589 \ud6c4 \uc0dd\uc131\ub418\ub294 \ud30c\uc77c:</p> <ul> <li><code>example/quickstart/dataset/toy_support_qa_v1/test.jsonl</code></li> <li><code>example/quickstart/dataset/toy_support_qa_v1/metadata.json</code></li> <li><code>example/quickstart/dataset/toy_support_qa_v1/schema.json</code></li> </ul>"},{"location":"usage/generator/#4-dataset_id-version-metadata","title":"4. dataset_id / version / metadata \uc815\ucc45","text":"<p>\uc77c\uad00\ub41c \uc7ac\ud604\uc131\uc744 \uc704\ud574 \ub2e4\uc74c \uc815\ucc45\uc744 \uad8c\uc7a5\ud569\ub2c8\ub2e4.</p> <ul> <li>dataset_id: \ub17c\ub9ac\uc801\uc73c\ub85c \ub3d9\uc77c\ud55c \ub370\uc774\ud130\uc14b \uacc4\uc5f4\uc758 ID</li> <li>version: \ub370\uc774\ud130 \ub0b4\uc6a9/\uc0d8\ud50c \uad6c\uc131\uc774 \ubc14\ub014 \ub54c\ub9c8\ub2e4 \uc99d\uac00 (<code>v1</code>, <code>v2</code>, ...)</li> <li>metadata.json \ud544\uc218 \uc815\ubcf4 \uc608\uc2dc:</li> <li><code>dataset_id</code>, <code>name</code>, <code>version</code>, <code>created_at</code></li> <li><code>generator_version</code>, <code>generator_code_commit</code></li> <li><code>sample_count</code></li> <li><code>filters</code> (min_len/max_len \ub4f1)</li> <li><code>sampling</code> (sample_size, sample_random)</li> <li><code>tag_stats</code>, <code>language_stats</code></li> </ul> <p>\uc6d0\ucc9c \ub370\uc774\ud130\ub098 \uc804\ucc98\ub9ac/\uc0d8\ud50c\ub9c1 \ub85c\uc9c1\uc774 \ubc14\ub00c\uc5b4 \uc0d8\ud50c \uc9d1\ud569\uc774 \ubc14\ub00c\ub294 \uacbd\uc6b0 \ubc18\ub4dc\uc2dc <code>version</code>\uc744 \uc62c\ub824 \uc8fc\ub294 \uac83\uc774 \uc88b\uc2b5\ub2c8\ub2e4.</p>"},{"location":"usage/overview/","title":"Framework Overview","text":"<p>\uc774 \ubb38\uc11c\ub294 <code>lm-eval-so</code> \ud504\ub808\uc784\uc6cc\ud06c\uc758 \ud070 \uadf8\ub9bc\uc744 \uc124\uba85\ud569\ub2c8\ub2e4.</p> <ul> <li>Core \ub3c4\uba54\uc778 \ubaa8\ub378</li> <li>Generator \u2192 Runner \u2192 Evaluator \ub370\uc774\ud130 \ud50c\ub85c\uc6b0</li> <li>Report \uad6c\uc870(Experiment/metrics/breakdown \ub4f1)\uc758 \uac1c\uc694</li> </ul>"},{"location":"usage/overview/#1-core","title":"1. Core \ub3c4\uba54\uc778 \ubaa8\ub378","text":"<p>\ud504\ub808\uc784\uc6cc\ud06c \uc804\uc5ed\uc5d0\uc11c \uacf5\uc720\ud558\ub294 \uacf5\ud1b5 \ubaa8\ub378\uc740 \ub300\ub7b5 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4.</p> <ul> <li>TestSample</li> <li><code>id</code>: \uc0d8\ud50c ID</li> <li><code>messages</code>: \ub300\ud654 \ub9e5\ub77d (<code>role</code>, <code>content</code> \ub85c \uad6c\uc131\ub41c \uba54\uc2dc\uc9c0 \ub9ac\uc2a4\ud2b8)</li> <li><code>expected</code>: \uae30\ub300 \ucd9c\ub825(\uc788\uc744 \uc218\ub3c4, \uc5c6\uc744 \uc218\ub3c4 \uc788\uc74c)</li> <li><code>tags</code>: \ud0dc\uadf8 \ub9ac\uc2a4\ud2b8 (task, domain, language \ub4f1)</li> <li> <p><code>metadata</code>: \uae38\uc774, \ud1a0\ud53d, \ub09c\uc774\ub3c4 \ub4f1\uc758 \ubd80\uac00 \uc815\ubcf4</p> </li> <li> <p>TestCase (\uc120\ud0dd\uc801 \uac1c\ub150)</p> </li> <li> <p>\uc5ec\ub7ec <code>TestSample</code> \uc744 \ud558\ub098\uc758 \uc2dc\ub098\ub9ac\uc624\ub85c \ubb36\uc744 \ub54c \uc0ac\uc6a9</p> </li> <li> <p>RunConfig</p> </li> <li>\uc5b4\ub5a4 \ubc31\uc5d4\ub4dc/\ubaa8\ub378\uc744 \uc5b4\ub5a4 \uc124\uc815\uc73c\ub85c \ub3cc\ub9b4\uc9c0\uc5d0 \ub300\ud55c \uad6c\uc131</li> <li> <p>\uc608: <code>backend=\"openai\"</code>, <code>model=\"gpt-4o-mini\"</code>, <code>parameters={\"temperature\": 0.0}</code></p> </li> <li> <p>RunResult</p> </li> <li>\ub2e8\uc77c <code>TestSample</code> \uc5d0 \ub300\ud574 \uc2e4\uc81c \ucc57\ubd07/\ubaa8\ub378\uc744 \ud638\ucd9c\ud55c \uacb0\uacfc</li> <li> <p>\ud3ec\ud568 \uc815\ubcf4 \uc608\uc2dc:</p> <ul> <li><code>sample_id</code>, <code>dataset_id</code>, <code>backend</code>, <code>run_config</code></li> <li>\uc694\uccad \uba54\uc2dc\uc9c0(<code>request_messages</code>), \uc751\ub2f5 \ud14d\uc2a4\ud2b8/\ud1a0\ud070 \uc0ac\uc6a9\ub7c9</li> <li><code>status</code> (ok / timeout / error / retry \ub4f1)</li> <li><code>latency_ms</code>, <code>trace_id</code>, <code>error</code> \uc815\ubcf4</li> </ul> </li> <li> <p>EvalScore</p> </li> <li>\ud55c metric\uc5d0 \ub300\ud55c \ub2e8\uc77c \uc0d8\ud50c\uc758 \uc810\uc218</li> <li><code>metric_name</code>, <code>value</code>, <code>detail</code>(\uc608: expected/answer \ud398\uc5b4, \ud0a4\uc6cc\ub4dc \ub9e4\uce6d \uc218, LLM Judge \uc138\ubd80 \uc815\ubcf4 \ub4f1)</li> </ul> <p>\uc774 \uacf5\ud1b5 \ubaa8\ub378\uc744 \uae30\uc900\uc73c\ub85c Generator/Runner/Evaluator\uac00 \ub290\uc2a8\ud558\uac8c \uacb0\ud569\ub429\ub2c8\ub2e4.</p>"},{"location":"usage/overview/#2-generator-runner-evaluator","title":"2. Generator \u2192 Runner \u2192 Evaluator \ub370\uc774\ud130 \ud50c\ub85c\uc6b0","text":""},{"location":"usage/overview/#21-generator-dataset","title":"2.1 Generator (Dataset \uc0dd\uc131)","text":"<p>\ubaa9\ud45c: \ub2e4\uc591\ud55c \ud3ec\ub9f7\uc758 \uc6d0\ucc9c \ub370\uc774\ud130\ub97c canonical <code>TestSample</code> \ub9ac\uc2a4\ud2b8\ub85c \uc815\uaddc\ud654\ud558\uace0, \ubc84\uc804\uc774 \ubd99\uc740 Dataset\uc73c\ub85c \uad00\ub9ac\ud569\ub2c8\ub2e4.</p> <p>\uc804\ud615\uc801\uc778 \ud50c\ub85c\uc6b0:</p> <ol> <li>\uc6d0\ucc9c \ub370\uc774\ud130 \ub85c\ub529</li> <li>CSV / JSONL / DB \ub4f1\uc5d0\uc11c row \ub2e8\uc704\ub85c \ubd88\ub7ec\uc624\uae30</li> <li>\uc815\uaddc\ud654 (Canonicalization)</li> <li>\uac01 row\ub97c <code>TestSample</code> \uad6c\uc870\ub85c \ub9e4\ud551</li> <li>\uc608: <code>system</code>, <code>user</code>, <code>expected</code>, <code>tags</code>, <code>lang</code> \uceec\ub7fc \u2192 <code>messages</code>/<code>expected</code>/<code>tags</code>/<code>metadata</code></li> <li>\ud544\ud130\ub9c1 / \uc0d8\ud50c\ub9c1</li> <li>\uae38\uc774, \uc5b8\uc5b4, \ud0dc\uadf8 \uae30\uc900 \ud544\ud130</li> <li>\ub79c\ub364 \uc0d8\ud50c\ub9c1 \ub610\ub294 \uc804\ub7b5\uc801 \uc0d8\ud50c\ub9c1</li> <li>\ucd9c\ub825</li> <li><code>test.jsonl</code>: <code>TestSample.to_dict()</code> \ub9ac\uc2a4\ud2b8</li> <li><code>metadata.json</code>: <code>dataset_id</code>, <code>name</code>, <code>version</code>, <code>created_at</code>, <code>sample_count</code>, tag/language \ubd84\ud3ec \ub4f1</li> <li><code>schema.json</code>: <code>TestSample</code> JSON Schema</li> </ol> <p>Quick Start \uc608\uc81c\uc5d0\uc11c\ub294:</p> <ul> <li><code>example/quickstart/data/toy_support_qa.csv</code> \u2192 <code>toy_support_qa_v1/test.jsonl</code> + <code>metadata.json</code></li> </ul>"},{"location":"usage/overview/#22-runner","title":"2.2 Runner (\ud14c\uc2a4\ud2b8 \uc2e4\ud589)","text":"<p>\ubaa9\ud45c: (Dataset \u00d7 Backend \u00d7 RunConfig) \uc870\ud569\uc5d0 \ub300\ud574 \uc2e4\uc81c \ucc57\ubd07/\ubaa8\ub378\uc744 \ud638\ucd9c\ud558\uace0, <code>RunResult</code> \ub808\ucf54\ub4dc \uc9d1\ud569\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4.</p> <p>\uc804\ud615\uc801\uc778 \ud50c\ub85c\uc6b0:</p> <ol> <li>Dataset \ub85c\ub4dc (<code>test.jsonl</code> + <code>metadata.json</code>)</li> <li>Backend \uc120\ud0dd (\uc608: <code>openai</code>)</li> <li>RunConfig \uad6c\uc131 (<code>model</code>, <code>temperature</code>, \uae30\ud0c0 \ud30c\ub77c\ubbf8\ud130)</li> <li>\ub3d9\uc2dc\uc131 / rate limit / retry \uc804\ub7b5\uc5d0 \ub530\ub77c \uac01 <code>TestSample</code> \uc5d0 \ub300\ud574 \uc694\uccad \uc804\uc1a1</li> <li>\uacb0\uacfc\ub97c <code>run_results.jsonl</code> \ubc0f <code>run_metadata.json</code> \ud615\ud0dc\ub85c \uc800\uc7a5</li> </ol> <p>Quick Start \uc608\uc81c\uc5d0\uc11c\ub294:</p> <ul> <li>Backend: <code>openai</code></li> <li>Model: <code>gpt-4o-mini</code> (\uae30\ubcf8\uac12, <code>QUICKSTART_MODEL</code> env\ub85c \ubcc0\uacbd \uac00\ub2a5)</li> <li>\ucd9c\ub825: <code>example/quickstart/runs/openai_&lt;model&gt;/run_results.jsonl</code></li> </ul>"},{"location":"usage/overview/#23-evaluator","title":"2.3 Evaluator (\ud3c9\uac00)","text":"<p>\ubaa9\ud45c: Dataset + RunResult\ub97c \uc870\ud569\ud574 \ub2e4\uc591\ud55c metric\uc744 \uacc4\uc0b0\ud558\uace0, per-sample score + aggregate report \ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4.</p> <p>\uc804\ud615\uc801\uc778 \ud50c\ub85c\uc6b0:</p> <ol> <li>Evaluator \uc124\uc815 \ub85c\ub4dc (<code>eval_toy.yaml</code> \ub4f1)</li> <li><code>run_config</code> (\uba54\ud0c0 \uc815\ubcf4\uc6a9)</li> <li><code>metrics</code> (\uc608: <code>exact_match</code>, <code>keyword_coverage</code>, <code>llm_judge</code>)</li> <li><code>breakdown</code> (tag / language / length \uae30\uc900 \uc9d1\uacc4 \uc124\uc815)</li> <li><code>report</code> \ud3ec\ub9f7 (JSON / Markdown \ub4f1)</li> <li>Dataset(<code>TestSample</code>), RunResult\ub97c sample_id \uae30\uc900\uc73c\ub85c \uc870\uc778</li> <li>\uac01 metric\uc5d0 \ub300\ud574 \ubaa8\ub4e0 (sample, run) \ud398\uc5b4\uc5d0 \uc810\uc218 \uacc4\uc0b0 \u2192 <code>EvalScore</code> \ub9ac\uc2a4\ud2b8 \uc0dd\uc131</li> <li>metric\ubcc4 \ud1b5\uacc4 \uacc4\uc0b0 (mean, std, sample_count)</li> <li>tag/length/language \ubcc4 breakdown \uc0dd\uc131</li> <li>LLM Judge \uad00\ub828 \uc138\ubd80 \uc815\ubcf4 \uc218\uc9d1 (prompt_id/version, criteria \ub4f1)</li> <li>\ucd5c\uc885 <code>EvaluationResult</code>/<code>EvaluationReport</code> \ub97c JSON/Markdown \ud30c\uc77c\ub85c \uc800\uc7a5</li> </ol> <p>Quick Start \uc608\uc81c\uc5d0\uc11c \uc0dd\uc131\ub418\ub294 \ub300\ud45c \ucd9c\ub825:</p> <ul> <li><code>summary.json</code> \u2014 metric\ubcc4 \uc694\uc57d \ud14c\uc774\ube14 (mean/std/sample_count)</li> <li><code>scores.jsonl</code> \u2014 per-sample <code>EvalScore</code> \ub808\ucf54\ub4dc</li> <li><code>report.md</code> \u2014 \uc0ac\ub78c\uc774 \uc77d\uae30 \uc88b\uc740 Markdown \ub9ac\ud3ec\ud2b8</li> </ul>"},{"location":"usage/overview/#3-report","title":"3. Report \uad6c\uc870 \uac1c\uc694","text":"<p>\ub9ac\ud3ec\ud2b8\ub294 \ubcf4\ud1b5 \ub2e4\uc74c\uacfc \uac19\uc740 \uad6c\uc870\ub97c \uac00\uc9d1\ub2c8\ub2e4.</p> <ul> <li>Experiment metadata</li> <li>\uc5b4\ub5a4 Dataset / Backend / RunConfig / EvaluatorConfig\ub85c \uc2e4\ud5d8\ud588\ub294\uc9c0 \uc694\uc57d</li> <li>Overall metrics summary</li> <li>metric\ubcc4 <code>mean</code>, <code>std</code>, <code>sample_count</code> \ud14c\uc774\ube14</li> <li>Breakdown</li> <li>tag / language / length \uae30\uc900\uc73c\ub85c metric \ubd84\ud3ec\ub97c \ub098\ub208 \ud14c\uc774\ube14/\uadf8\ub798\ud504</li> <li>Error cases / Low-score samples</li> <li>status\uac00 ok\uac00 \uc544\ub2cc RunResult, \ub610\ub294 \uc810\uc218\uac00 \ub0ae\uc740 \uc0d8\ud50c \ubaa9\ub85d</li> <li>LLM Judge \uc138\ubd80 \uc815\ubcf4 (\uc120\ud0dd)</li> <li><code>prompt_id</code>, <code>prompt_version</code>, <code>criteria</code>, \ud3c9\uac00\uc5d0 \uc0ac\uc6a9\ub41c sample \uc9d1\ud569 ID \ub4f1</li> </ul> <p>\uc774 \uad6c\uc870\ub97c \uc9c0\ud0a4\uba74, \uc5ec\ub7ec \uc2e4\ud5d8/\ubaa8\ub378\uc744 \ube44\uad50\ud558\ub294 \ub9ac\ud3ec\ud2b8\ub97c \uc791\uc131\ud560 \ub54c\ub3c4 \uc77c\uad00\uc131\uc744 \uc720\uc9c0\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p> <p>\ub2e4\uc74c\uc73c\ub85c\ub294 \uac01 \ubaa8\ub4c8\ubcc4 \uc0ac\uc6a9\ubc95 \ubb38\uc11c\ub97c \ucc38\uace0\ud558\uc138\uc694.</p> <ul> <li>Generator \uc0ac\uc6a9\ubc95</li> <li>Runner \uc0ac\uc6a9\ubc95</li> <li>Evaluator \uc0ac\uc6a9\ubc95</li> </ul>"},{"location":"usage/quickstart-e2e/","title":"Quick Start: End-to-End \uc608\uc81c","text":"<p>\uc774 \ubb38\uc11c\ub294 <code>example/quickstart/</code> \ub514\ub809\ud130\ub9ac\uc5d0 \uc788\ub294 toy_support_qa \uc608\uc81c\ub97c \uae30\ubc18\uc73c\ub85c, Generator \u2192 Runner \u2192 Evaluator \uc804\uccb4 \ud50c\ub85c\uc6b0\ub97c \ud55c \ubc88\uc5d0 \uc2e4\ud589\ud558\ub294 \ubc29\ubc95\uc744 \uc815\ub9ac\ud569\ub2c8\ub2e4.</p>"},{"location":"usage/quickstart-e2e/#1","title":"1. \uc0ac\uc804 \uc900\ube44","text":""},{"location":"usage/quickstart-e2e/#11","title":"1.1 \uc758\uc874\uc131 \uc124\uce58","text":"<pre><code>python -m pip install -r requirements.txt\n</code></pre>"},{"location":"usage/quickstart-e2e/#12-openai-api","title":"1.2 OpenAI API \ud0a4 \uc124\uc815","text":"<pre><code>export OPENAI_API_KEY=\"sk-...\"\nexport QUICKSTART_MODEL=\"gpt-4o-mini\"  # \uc120\ud0dd, \uc0dd\ub7b5 \uc2dc \uae30\ubcf8 gpt-4o-mini\n</code></pre>"},{"location":"usage/quickstart-e2e/#2-run_quickstartsh","title":"2. \ud55c \ubc88\uc5d0 \uc2e4\ud589 (run_quickstart.sh)","text":"<p>\uc544\ub798 \uc2a4\ud06c\ub9bd\ud2b8\ub294 Generator \u2192 Runner \u2192 Evaluator\ub97c \uc21c\uc11c\ub300\ub85c \uc2e4\ud589\ud569\ub2c8\ub2e4.</p> <pre><code>bash example/quickstart/run_quickstart.sh\n</code></pre> <p>\ub0b4\ubd80 \ub2e8\uacc4\ub294 \ub300\ub7b5 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4.</p> <ol> <li>Generator</li> <li>\uc785\ub825: <code>example/quickstart/data/toy_support_qa.csv</code></li> <li>\ucd9c\ub825: <code>example/quickstart/dataset/toy_support_qa_v1/</code><ul> <li><code>test.jsonl</code></li> <li><code>metadata.json</code></li> <li><code>schema.json</code></li> </ul> </li> <li>Runner (OpenAI backend)</li> <li>Dataset: <code>toy_support_qa_v1</code></li> <li>Backend: <code>openai</code></li> <li>Model: <code>QUICKSTART_MODEL</code> (\uae30\ubcf8: <code>gpt-4o-mini</code>)</li> <li>\ucd9c\ub825: <code>example/quickstart/runs/openai_&lt;model&gt;/run_results.jsonl</code>, <code>run_metadata.json</code></li> <li>Evaluator</li> <li>Dataset + RunResult + \uc124\uc815(<code>eval_toy.yaml</code>)\uc744 \uc0ac\uc6a9\ud574</li> <li><code>exact_match</code> / <code>keyword_coverage</code> \uba54\ud2b8\ub9ad \ud3c9\uac00 \uc218\ud589</li> <li>\ucd9c\ub825: <code>example/quickstart/reports/</code> \uc544\ub798 JSON/Markdown \ub9ac\ud3ec\ud2b8</li> </ol> <p>\uc131\uacf5 \uc2dc \ub300\ub7b5 \ub2e4\uc74c\uacfc \uac19\uc740 \ub85c\uadf8\ub97c \ubcfc \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p> <pre><code>[quickstart] 1/3: Generating canonical dataset...\n/home/.../example/quickstart/dataset/toy_support_qa_v1\n[quickstart] 2/3: Running Runner against OpenAI backend...\nINFO:lm_eval_so.runner:Starting run: dataset=toy_support_qa backend=openai model=gpt-4o-mini samples=3\n...\n[quickstart] 3/3: Evaluating run results...\n/home/.../example/quickstart/reports/summary.json\n/home/.../example/quickstart/reports/scores.jsonl\n/home/.../example/quickstart/reports/report.md\n[quickstart] Done. Reports written under example/quickstart/reports\n</code></pre>"},{"location":"usage/quickstart-e2e/#3","title":"3. \uc0dd\uc131\ub418\ub294 \ud30c\uc77c \uad6c\uc870","text":"<p>\uc2e4\ud589 \ud6c4 Quick Start \uad00\ub828 \ub514\ub809\ud130\ub9ac \uad6c\uc870\ub294 \ub300\ub7b5 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4.</p> <pre><code>example/quickstart/\n  data/\n    toy_support_qa.csv\n  dataset/\n    toy_support_qa_v1/\n      test.jsonl\n      metadata.json\n      schema.json\n  runs/\n    openai_gpt-4o-mini/   # QUICKSTART_MODEL\uc5d0 \ub530\ub77c \ub514\ub809\ud130\ub9ac \uc774\ub984\uc774 \ub2ec\ub77c\uc9c8 \uc218 \uc788\uc74c\n      run_results.jsonl\n      run_metadata.json\n  config/\n    eval_toy.yaml\n  reports/\n    summary.json\n    scores.jsonl\n    report.md\n  run_quickstart.sh\n</code></pre>"},{"location":"usage/quickstart-e2e/#4","title":"4. \ub9ac\ud3ec\ud2b8 \ud574\uc11d\ud558\uae30","text":"<p><code>example/quickstart/reports/report.md</code> \ub294 \uc0ac\ub78c\uc774 \uc77d\uae30 \uc88b\uc740 Markdown \ub9ac\ud3ec\ud2b8\uc785\ub2c8\ub2e4.</p> <p>\uc77c\ubc18\uc801\uc73c\ub85c \ub2e4\uc74c \ub0b4\uc6a9\uc744 \ud3ec\ud568\ud569\ub2c8\ub2e4.</p> <ul> <li>Experiment metadata</li> <li>dataset \uc815\ubcf4 (id/name/version, sample_count \ub4f1)</li> <li>run_config (backend, model, \ud30c\ub77c\ubbf8\ud130)</li> <li>evaluator_config (metrics/breakdown/report \uc124\uc815)</li> <li>Metrics summary</li> <li><code>exact_match</code>, <code>keyword_coverage</code> \ub4f1 metric\ubcc4 mean/std/sample_count</li> <li>Breakdown</li> <li>tag / language / length \uae30\uc900 metric \ubd84\ud3ec</li> <li>Error cases</li> <li>status\uac00 ok\uac00 \uc544\ub2cc RunResult\ub4e4\uc758 \uc694\uc57d (Quick Start \uc608\uc81c\uc5d0\uc11c\ub294 \ub300\ubd80\ubd84 ok)</li> </ul> <p>\uc774\ub97c \uc2dc\uc791\uc810\uc73c\ub85c \uc0bc\uc544, \ub354 \ud070 Dataset/\ub2e4\uc591\ud55c Backend/Metric \uc870\ud569\uc73c\ub85c \ud655\uc7a5\ud574 \ub098\uac08 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p>"},{"location":"usage/report-schema/","title":"Report Schema (EvaluationResult / EvaluationReport)","text":"<p>\uc774 \ubb38\uc11c\ub294 Evaluator\uac00 \uc0dd\uc131\ud558\ub294 \uacb0\uacfc \ud30c\uc77c \uad6c\uc870\ub97c \uc815\ub9ac\ud569\ub2c8\ub2e4.</p> <ul> <li>per-sample \uc810\uc218: <code>EvalScore</code> \ub9ac\uc2a4\ud2b8 (<code>scores.jsonl</code>)</li> <li>\uc9d1\uacc4 \ub9ac\ud3ec\ud2b8: <code>EvaluationReport</code> (<code>summary.json</code>, <code>report.md</code> \ub4f1)</li> </ul> <p>\uc544\ub798 \uc124\uba85\uc740 <code>src/lm_eval_so/evaluator/domain.py</code> \uc758 \ub3c4\uba54\uc778 \ubaa8\ub378\uc744 \uae30\uc900\uc73c\ub85c \ud569\ub2c8\ub2e4.</p>"},{"location":"usage/report-schema/#1-core","title":"1. Core \ub370\uc774\ud130 \uad6c\uc870","text":""},{"location":"usage/report-schema/#11-datasetmetadata","title":"1.1 DatasetMetadata","text":"<p><code>metadata.json</code> \uc5d0\uc11c \uc77d\uc5b4\uc624\ub294 Dataset \uba54\ud0c0\ub370\uc774\ud130\uc785\ub2c8\ub2e4.</p> <p>\uc911\uc694 \ud544\ub4dc:</p> <ul> <li><code>dataset_id: str</code></li> <li><code>version: str</code></li> <li><code>name: str | null</code></li> <li><code>source: any | null</code> \u2014 \uc6d0\ucc9c \ub370\uc774\ud130 \ucd9c\ucc98</li> <li><code>created_at: str | null</code></li> <li><code>generator_commit: str | null</code> \u2014 generator \ucf54\ub4dc \ucee4\ubc0b \ud574\uc2dc</li> <li><code>filters: object | null</code> \u2014 \uc804\ucc98\ub9ac/\ud544\ud130\ub9c1 \uc870\uac74</li> <li><code>sampling: object | null</code> \u2014 \uc0d8\ud50c\ub9c1 \uc804\ub7b5 \uc815\ubcf4</li> <li><code>counts: object | null</code> \u2014 \uc0d8\ud50c \uac1c\uc218 \ub4f1 \uce74\uc6b4\ud2b8 \uc815\ubcf4 (\uc608: <code>{\"sample_count\": 3}</code>)</li> <li><code>languages: object | null</code> \u2014 \uc5b8\uc5b4 \ubd84\ud3ec</li> <li><code>tags: object | null</code> \u2014 \ud0dc\uadf8 \ubd84\ud3ec</li> <li><code>extra: object</code> \u2014 \uc704\uc5d0 \uba85\uc2dc\ub418\uc9c0 \uc54a\uc740 \ucd94\uac00 \ud544\ub4dc</li> </ul>"},{"location":"usage/report-schema/#12-testsamplerecord","title":"1.2 TestSampleRecord","text":"<p>per-sample Dataset \ub808\ucf54\ub4dc\uc785\ub2c8\ub2e4. Evaluator\uac00 dataset JSONL\uc744 \uc77d\uc744 \ub54c \uc0ac\uc6a9\ud569\ub2c8\ub2e4.</p> <ul> <li><code>id: str</code></li> <li><code>messages: Message[]</code> \u2014 canonical \uba54\uc2dc\uc9c0 \ub9ac\uc2a4\ud2b8 (<code>role</code>, <code>content</code>, <code>name</code>, <code>metadata</code> \ub4f1)</li> <li><code>expected: any | null</code> \u2014 \ucc38\uc870 \uc815\ub2f5 (\uc788\uc744 \uc218\ub3c4, \uc5c6\uc744 \uc218\ub3c4 \uc788\uc74c)</li> <li><code>tags: string[]</code> \u2014 \ud0dc\uadf8 \ub9ac\uc2a4\ud2b8</li> <li><code>metadata: object</code> \u2014 \uc784\uc758 \uba54\ud0c0\ub370\uc774\ud130 (\uc608: <code>{\"language\": \"ko\"}</code>)</li> <li>\ud30c\uc0dd \uc18d\uc131</li> <li><code>language: str | null</code> \u2014 <code>metadata[\"language\"]</code></li> <li><code>length_bucket: \"short\" | \"medium\" | \"long\"</code> \u2014 messages content \uae38\uc774\ub85c\ubd80\ud130 \ucd94\ub860</li> </ul>"},{"location":"usage/report-schema/#13-runrecord","title":"1.3 RunRecord","text":"<p>Runner\uac00 \uc0dd\uc131\ud55c per-sample \uc2e4\ud589 \uacb0\uacfc\ub97c Evaluator\uc6a9\uc73c\ub85c \uc815\uaddc\ud654\ud55c \uad6c\uc870\uc785\ub2c8\ub2e4.</p> <ul> <li><code>sample_id: str</code></li> <li><code>dataset_id: str | null</code></li> <li><code>backend: str</code> \u2014 \uc608: <code>\"openai\"</code></li> <li><code>run_config: object</code> \u2014 Runner\uc5d0 \uc0ac\uc6a9\ub41c \uc124\uc815 \uc804\uccb4</li> <li><code>response_text: str | null</code> \u2014 \uc751\ub2f5 \ud14d\uc2a4\ud2b8 (\uc5c6\uc73c\uba74 null)</li> <li><code>status: str</code> \u2014 <code>ok</code>, <code>timeout</code>, <code>error</code>, <code>retry</code> \ub4f1</li> <li><code>latency_ms: float | null</code></li> <li><code>trace_id: str</code></li> <li><code>attempts: int</code></li> <li><code>error: object | null</code> \u2014 \uc624\ub958 \uc815\ubcf4 (message, error_type, status_code \ub4f1)</li> <li><code>raw: object</code> \u2014 \uc6d0\ubcf8 RunResult \ub808\ucf54\ub4dc \uc804\uccb4 (LLM Judge \uc810\uc218 \ub4f1\ub3c4 \ud3ec\ud568)</li> </ul>"},{"location":"usage/report-schema/#14-evalscore-per-sample-metric","title":"1.4 EvalScore (per-sample metric \uacb0\uacfc)","text":"<p>\ud558\ub098\uc758 metric\uc5d0 \ub300\ud574 \ud558\ub098\uc758 \uc0d8\ud50c\uc5d0\uc11c \ub098\uc628 \uc810\uc218\uc785\ub2c8\ub2e4.</p> <ul> <li><code>sample_id: str</code></li> <li><code>metric: str</code> \u2014 metric \uc774\ub984 (<code>exact_match</code>, <code>keyword_coverage</code>, <code>llm_judge</code> \ub4f1)</li> <li><code>value: float</code> \u2014 0.0~1.0 \ubc94\uc704\ub97c \uad8c\uc7a5</li> <li><code>tags: string[]</code> \u2014 \uc0d8\ud50c \ud0dc\uadf8</li> <li><code>language: str | null</code> \u2014 \uc0d8\ud50c \uc5b8\uc5b4</li> <li><code>length_bucket: str | null</code> \u2014 <code>short</code> / <code>medium</code> / <code>long</code></li> <li><code>detail: object</code> \u2014 metric \uc138\ubd80 \uc815\ubcf4 (expected/answer, matched keywords, LLM Judge raw score \ub4f1)</li> </ul>"},{"location":"usage/report-schema/#15-metricsummary-metricbreakdown","title":"1.5 MetricSummary / MetricBreakdown","text":"<p>\uc9d1\uacc4 \ub808\ubca8 \ud1b5\uacc4\ub97c \ud45c\ud604\ud569\ub2c8\ub2e4.</p> <p>MetricSummary (\uc804\uccb4 \uc694\uc57d):</p> <ul> <li><code>metric: str</code></li> <li><code>mean: float</code></li> <li><code>std: float</code></li> <li><code>sample_count: int</code></li> </ul> <p>MetricBreakdown (dimension\ubcc4 \ubd84\ud574):</p> <ul> <li><code>metric: str</code></li> <li><code>dimension: str</code> \u2014 \uc608: <code>\"tag\"</code>, <code>\"language\"</code>, <code>\"length\"</code></li> <li><code>bucket: str</code> \u2014 \uc608: \ud0dc\uadf8 \uc774\ub984, \uc5b8\uc5b4 \ucf54\ub4dc, length_bucket</li> <li><code>mean: float</code></li> <li><code>std: float</code></li> <li><code>sample_count: int</code></li> </ul>"},{"location":"usage/report-schema/#16-errorcase","title":"1.6 ErrorCase","text":"<p>\uc2e4\ud589 \ub2e8\uacc4\uc5d0\uc11c status\uac00 ok\uac00 \uc544\ub2c8\uc5c8\ub358 \uc0d8\ud50c\uc5d0 \ub300\ud55c \uc815\ubcf4\uc785\ub2c8\ub2e4.</p> <ul> <li><code>sample_id: str</code></li> <li><code>status: str</code> \u2014 <code>timeout</code>, <code>error</code>, <code>retry</code> \ub4f1</li> <li><code>trace_id: str</code></li> <li><code>message: str | null</code> \u2014 \uc5d0\ub7ec \uba54\uc2dc\uc9c0</li> <li><code>latency_ms: float | null</code></li> <li><code>backend: str | null</code></li> </ul>"},{"location":"usage/report-schema/#17-llmjudgedetail","title":"1.7 LLMJudgeDetail","text":"<p>LLM Judge \uae30\ubc18 metric\ub4e4\uc758 \uba54\ud0c0 \uc815\ubcf4\ub97c \ubaa8\uc740 \uc694\uc57d\uc785\ub2c8\ub2e4.</p> <ul> <li><code>metric: str</code> \u2014 \uc608: <code>\"llm_judge\"</code></li> <li><code>prompt_id: str</code></li> <li><code>prompt_version: str</code></li> <li><code>language: str | null</code> \u2014 \ub2e8\uc77c \uc5b8\uc5b4\ub9cc \uc788\uc73c\uba74 \ud574\ub2f9 \uc5b8\uc5b4, \ud63c\ud569\uc774\uba74 null</li> <li><code>criteria: string[]</code> \u2014 \ud3c9\uac00 \uae30\uc900 \ub9ac\uc2a4\ud2b8</li> <li><code>sample_count: int</code></li> <li><code>sample_ids: string[]</code> \u2014 Judge \ud3c9\uac00\uc5d0 \uc0ac\uc6a9\ub41c \uc0d8\ud50c ID \ub9ac\uc2a4\ud2b8</li> </ul>"},{"location":"usage/report-schema/#18-experimentmetadata-evaluationreport-evaluationresult","title":"1.8 ExperimentMetadata / EvaluationReport / EvaluationResult","text":"<p>ExperimentMetadata</p> <ul> <li><code>dataset: DatasetMetadata</code></li> <li><code>run_config: object</code> \u2014 \uc774 \ud3c9\uac00\uac00 \uc5b4\ub5a4 RunConfig \ud658\uacbd\uc5d0 \ub300\ud55c \uac83\uc778\uc9c0 (backend/model/parameters)</li> <li><code>evaluator_config: object</code> \u2014 Evaluator \uc124\uc815 \uc804\uccb4 (<code>metrics</code>, <code>breakdown</code>, <code>report</code> \ub4f1)</li> </ul> <p>EvaluationReport</p> <ul> <li><code>experiment: ExperimentMetadata</code></li> <li><code>summaries: MetricSummary[]</code></li> <li><code>breakdowns: MetricBreakdown[]</code></li> <li><code>error_cases: ErrorCase[]</code></li> <li><code>llm_judge_details: LLMJudgeDetail[]</code></li> </ul> <p>EvaluationResult</p> <ul> <li><code>scores: EvalScore[]</code> \u2014 per-sample \uc810\uc218 \uc804\uccb4</li> <li><code>report: EvaluationReport</code> \u2014 \uc9d1\uacc4 \ub9ac\ud3ec\ud2b8</li> </ul>"},{"location":"usage/report-schema/#2-json","title":"2. JSON \uc608\uc2dc","text":"<p>\uc544\ub798\ub294 \ub9e4\uc6b0 \ub2e8\uc21c\ud654\ud55c <code>EvaluationResult</code> JSON \uc608\uc2dc\uc785\ub2c8\ub2e4.</p> <pre><code>{\n  \"scores\": [\n    {\n      \"sample_id\": \"toy-001\",\n      \"metric\": \"exact_match\",\n      \"value\": 1.0,\n      \"tags\": [\"toy\", \"support\", \"ko\"],\n      \"language\": \"ko\",\n      \"length_bucket\": \"short\",\n      \"detail\": {\n        \"expected\": \"\ube44\ubc00\ubc88\ud638 \uc7ac\uc124\uc815\uc744 \uc704\ud574 \ub4f1\ub85d\ub41c \uc774\uba54\uc77c\uc744 \ud655\uc778\ud558\uc138\uc694.\",\n        \"answer\": \"\ube44\ubc00\ubc88\ud638 \uc7ac\uc124\uc815\uc744 \uc704\ud574 \ub4f1\ub85d\ub41c \uc774\uba54\uc77c\uc744 \ud655\uc778\ud558\uc138\uc694.\",\n        \"match\": true\n      }\n    },\n    {\n      \"sample_id\": \"toy-001\",\n      \"metric\": \"keyword_coverage\",\n      \"value\": 1.0,\n      \"tags\": [\"toy\", \"support\", \"ko\"],\n      \"language\": \"ko\",\n      \"length_bucket\": \"short\",\n      \"detail\": {\n        \"matched\": 1,\n        \"total_keywords\": 1\n      }\n    }\n  ],\n  \"report\": {\n    \"experiment\": {\n      \"dataset\": {\n        \"dataset_id\": \"toy_support_qa\",\n        \"version\": \"v1\",\n        \"name\": \"Toy Support QA\",\n        \"created_at\": \"2025-11-23T07:52:40Z\",\n        \"counts\": {\"sample_count\": 3},\n        \"languages\": {\"ko\": 2, \"en\": 1},\n        \"tags\": {\"toy\": 3, \"support\": 3}\n      },\n      \"run_config\": {\n        \"backend\": \"openai\",\n        \"model\": \"gpt-4o-mini\",\n        \"parameters\": {\"temperature\": 0}\n      },\n      \"evaluator_config\": {\n        \"metrics\": [\n          {\"type\": \"exact_match\", \"name\": \"exact_match\"},\n          {\"type\": \"keyword_coverage\", \"name\": \"keyword_coverage\"}\n        ],\n        \"breakdown\": {\"dimensions\": [\"tag\", \"language\", \"length\"]},\n        \"report\": {\"formats\": [\"json\", \"markdown\"]}\n      }\n    },\n    \"summaries\": [\n      {\n        \"metric\": \"exact_match\",\n        \"mean\": 0.66,\n        \"std\": 0.47,\n        \"sample_count\": 3\n      },\n      {\n        \"metric\": \"keyword_coverage\",\n        \"mean\": 0.8,\n        \"std\": 0.2,\n        \"sample_count\": 3\n      }\n    ],\n    \"breakdowns\": [\n      {\n        \"metric\": \"exact_match\",\n        \"dimension\": \"language\",\n        \"bucket\": \"ko\",\n        \"mean\": 1.0,\n        \"std\": 0.0,\n        \"sample_count\": 2\n      },\n      {\n        \"metric\": \"exact_match\",\n        \"dimension\": \"language\",\n        \"bucket\": \"en\",\n        \"mean\": 0.0,\n        \"std\": 0.0,\n        \"sample_count\": 1\n      }\n    ],\n    \"error_cases\": [],\n    \"llm_judge_details\": []\n  }\n}\n</code></pre> <p>\uc2e4\uc81c Quick Start \uc608\uc81c\uc758 <code>summary.json</code> / <code>scores.jsonl</code>\ub294 \uc704 \uad6c\uc870\ub97c \ub354 \ub9ce\uc740 metric\uacfc breakdown\uc73c\ub85c \ud655\uc7a5\ud55c \ud615\ud0dc\uc785\ub2c8\ub2e4.</p>"},{"location":"usage/report-schema/#3-markdown","title":"3. Markdown \ub9ac\ud3ec\ud2b8 \uc608\uc2dc \uad6c\uc870","text":"<p><code>report.md</code> \ub294 \uc0ac\ub78c\uc774 \uc77d\uae30 \uc88b\uc740 Markdown \ub9ac\ud3ec\ud2b8\ub85c, \ubcf4\ud1b5 \ub2e4\uc74c \uc139\uc158\uc744 \ud3ec\ud568\ud569\ub2c8\ub2e4.</p> <pre><code># Experiment\n\n- Dataset: toy_support_qa v1 (3 samples)\n- Backend: openai (model=gpt-4o-mini)\n- Evaluator config: metrics=[exact_match, keyword_coverage]\n\n## Overall Metrics\n\n| metric            | mean | std  | sample_count |\n|-------------------|------|------|--------------|\n| exact_match       | 0.66 | 0.47 | 3            |\n| keyword_coverage  | 0.80 | 0.20 | 3            |\n\n## Breakdown by language\n\n| metric      | language | mean | std  | sample_count |\n|-------------|----------|------|------|--------------|\n| exact_match | ko       | 1.0  | 0.0  | 2            |\n| exact_match | en       | 0.0  | 0.0  | 1            |\n\n## Error Cases\n\nNo error cases. (all runs status=ok)\n\n## Notes\n\n- All Korean samples were answered correctly.\n- English sample shows a mismatch with the reference answer.\n</code></pre> <p>\uc2e4\uc81c \uad6c\ud604\ub41c Markdown \ub9ac\ud3ec\ud2b8 \uad6c\uc870\ub294 \ucf54\ub4dc(<code>json_reporter.py</code> / <code>markdown_reporter.py</code>)\uc5d0 \ub530\ub77c \uc870\uae08\uc529 \ub2e4\ub97c \uc218 \uc788\uc9c0\ub9cc, \uc704\uc640 \uac19\uc774 \ub2e4\uc74c 4\uac00\uc9c0\ub97c \ud56d\uc0c1 \ud3ec\ud568\ud558\ub3c4\ub85d \uc124\uacc4\ud558\ub294 \uac83\uc744 \uad8c\uc7a5\ud569\ub2c8\ub2e4.</p> <ol> <li>Experiment metadata (dataset / backend / run_config / evaluator_config \uc694\uc57d)</li> <li>Overall metrics summary (metric\ubcc4 mean/std/sample_count)</li> <li>Breakdown (tag / language / length \uae30\uc900 \ud14c\uc774\ube14)</li> <li>Error cases / LLM Judge \uc138\ubd80 \uc815\ubcf4 (\ube44\uc815\uc0c1 \uc751\ub2f5/\ub0ae\uc740 \uc810\uc218 \uc0d8\ud50c)</li> </ol>"},{"location":"usage/report-schema/#4-report","title":"4. Report \uc124\uacc4 \uc2dc \uccb4\ud06c\ub9ac\uc2a4\ud2b8","text":"<p>\ub9ac\ud3ec\ud2b8 \uad6c\uc870\ub97c \ud655\uc7a5/\ubcc0\uacbd\ud560 \ub54c\ub294 \ub2e4\uc74c\uc744 \uc810\uac80\ud558\ub294 \uac83\uc774 \uc88b\uc2b5\ub2c8\ub2e4.</p> <ul> <li>Experiment \ub2e8\uc704\uac00 \uba85\ud655\ud55c\uac00?</li> <li>(Dataset \u00d7 Backend \u00d7 RunConfig \u00d7 EvaluatorConfig) \uc870\ud569\uc774 \ud558\ub098\uc758 Experiment</li> <li>\ubaa8\ub4e0 metric\uc5d0 \ub300\ud574:</li> <li>per-sample <code>EvalScore</code> \uac00 \uc874\uc7ac\ud558\ub294\uac00?</li> <li>summary(<code>MetricSummary</code>)\uc640 breakdown(<code>MetricBreakdown</code>)\uac00 \uc77c\uad00\ub41c \uc2a4\ud0a4\ub9c8\ub97c \ub530\ub974\ub294\uac00?</li> <li>ErrorCase/LLMJudgeDetail\uc774 \ubcc4\ub3c4 \uc139\uc158\uc73c\ub85c \uc815\ub9ac\ub418\uc5b4 \uc788\ub294\uac00?</li> <li>JSON/Markdown \ub9ac\ud3ec\ud2b8 \ubaa8\ub450\uc5d0\uc11c \ub3d9\uc77c\ud55c \uc815\ubcf4\uac00 \uc7ac\ud604 \uac00\ub2a5\ud55c\uac00?</li> </ul> <p>\uc774 \uae30\uc900\uc744 \uc9c0\ud0a4\uba74, \uc5ec\ub7ec \ubaa8\ub378/\ubc84\uc804/\uc124\uc815\uc744 \ube44\uad50\ud558\ub294 \uc0c1\uc704 \uc2e4\ud5d8 \ub9ac\ud3ec\ud2b8\ub97c \ub9cc\ub4e4 \ub54c\ub3c4 \uc2a4\ud0a4\ub9c8\uac00 \ud754\ub4e4\ub9ac\uc9c0 \uc54a\uace0 \uc77c\uad00\uc131\uc744 \uc720\uc9c0\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p>"},{"location":"usage/runner/","title":"Runner \uc0ac\uc6a9\ubc95","text":"<p>\uc774 \ubb38\uc11c\ub294 canonical Dataset\uc744 \uc2e4\uc81c \ucc57\ubd07/\ubaa8\ub378\uc5d0 \uc2e4\ud589\uc2dc\ucf1c <code>RunResult</code>\ub97c \uc0dd\uc131\ud558\ub294 Runner \ubaa8\ub4c8 \uc0ac\uc6a9 \ubc29\ubc95\uc744 \uc815\ub9ac\ud569\ub2c8\ub2e4.</p>"},{"location":"usage/runner/#1","title":"1. \uc5ed\ud560","text":"<p>Runner\ub294 \ub2e4\uc74c\uc744 \ub2f4\ub2f9\ud569\ub2c8\ub2e4.</p> <ol> <li>Dataset(<code>test.jsonl</code> + <code>metadata.json</code>) \ub85c\ub4dc</li> <li>Backend/\ubaa8\ub378/\ud30c\ub77c\ubbf8\ud130(RunConfig) \uad6c\uc131</li> <li>\ub3d9\uc2dc\uc131/timeout/retry/rate-limit \uc804\ub7b5 \ud558\uc5d0 \uac01 <code>TestSample</code> \uc5d0 \ub300\ud574 \uc694\uccad \uc804\uc1a1</li> <li>\uc751\ub2f5\uacfc \uba54\ud0c0\ub370\uc774\ud130\ub97c <code>RunResult</code> \ub808\ucf54\ub4dc\ub85c \ubaa8\uc544\uc11c JSONL \ud30c\uc77c\ub85c \uc800\uc7a5</li> </ol>"},{"location":"usage/runner/#2-multi-turn","title":"2. Multi-turn \ub300\ud654 \uc9c0\uc6d0","text":"<p>Runner\ub294 \ub2e8\uc21c 1-turn(User Question -&gt; Answer) \ubfd0\ub9cc \uc544\ub2c8\ub77c, Multi-turn \ub300\ud654 \ubb38\ub9e5\uc744 \uc720\uc9c0\ud558\uba70 \ud14c\uc2a4\ud2b8\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p> <ul> <li><code>TestSample</code>\uc758 <code>messages</code> \ud544\ub4dc\uc5d0 \uc5ec\ub7ec \ud134\uc758 \ub300\ud654(<code>user</code>, <code>assistant</code>, <code>user</code>, ...)\uac00 \ud3ec\ud568\ub418\uc5b4 \uc788\uc73c\uba74,</li> <li>Runner\ub294 \uc774\ub97c \uc21c\uc11c\ub300\ub85c \ubc31\uc5d4\ub4dc\uc5d0 \uc804\ub2ec\ud558\uc5ec \uc804\uccb4 \ubb38\ub9e5\uc744 \ubc18\uc601\ud55c \uc751\ub2f5\uc744 \uc694\uccad\ud569\ub2c8\ub2e4.</li> </ul> <p>\uc608\ub97c \ub4e4\uc5b4 \ub370\uc774\ud130\uc14b\uc774 \ub2e4\uc74c\uacfc \uac19\uc774 \uad6c\uc131\ub41c \uacbd\uc6b0:</p> <pre><code>[\n  {\"role\": \"user\", \"content\": \"Hello\"},\n  {\"role\": \"assistant\", \"content\": \"Hi there!\"},\n  {\"role\": \"user\", \"content\": \"What's the weather?\"}\n]\n</code></pre> <p>Runner\ub294 \uc774 \uc804\uccb4 \ub9ac\uc2a4\ud2b8\ub97c \ubc31\uc5d4\ub4dc\uc758 <code>messages</code> \uc778\uc790\ub85c \uc804\ub2ec\ud569\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 \uc774\uc804 \ub300\ud654 \ub0b4\uc6a9(\"Hello\" -&gt; \"Hi there!\")\uc744 \uae30\uc5b5\ud558\ub294\uc9c0 \ud14c\uc2a4\ud2b8\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p>"},{"location":"usage/runner/#3-cli","title":"3. CLI \uac1c\uc694","text":"<p>Runner\ub294 <code>python -m lm_eval_so.runner.cli</code> \ud615\ud0dc\uc758 CLI \uc5d4\ud2b8\ub9ac\ud3ec\uc778\ud2b8\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4.</p> <pre><code>python -m lm_eval_so.runner.cli --help\n</code></pre> <p>\uc8fc\uc694 \uc778\uc790:</p> <ul> <li>Dataset</li> <li><code>--dataset</code>: Dataset JSONL \uacbd\ub85c \ub610\ub294 Dataset \ub514\ub809\ud130\ub9ac</li> <li><code>--metadata</code>: <code>metadata.json</code> \uacbd\ub85c (\ub514\ub809\ud130\ub9ac\ub85c \uc9c0\uc815 \uc2dc \uc0dd\ub7b5 \uac00\ub2a5)</li> <li>Backend \uc120\ud0dd</li> <li><code>--backend</code>: backend \uc774\ub984 (\uc608: <code>openai</code>)</li> <li><code>--model</code>: backend\uc5d0\uc11c \uc0ac\uc6a9\ud560 \ubaa8\ub378 ID (\uc608: <code>gpt-4o-mini</code>)</li> <li>RunConfig \ud30c\ub77c\ubbf8\ud130</li> <li><code>--param key=value</code>: RunConfig.parameters \uc5d0 \ub4e4\uc5b4\uac08 \uac12 (\ubc18\ubcf5 \uc0ac\uc6a9 \uac00\ub2a5)</li> <li><code>--backend-opt key=value</code>: backend \uc635\uc158(\uc608: api_base, request_defaults \ub4f1)</li> <li>Runner \uc635\uc158</li> <li><code>--engine</code>: \uc2e4\ud589 \uc5d4\uc9c4 (\ud604\uc7ac sync \ub178\ucd9c)</li> <li><code>--max-concurrency</code>: \ub3d9\uc2dc \uc2e4\ud589 \uac1c\uc218</li> <li><code>--timeout</code>: \uc0d8\ud50c\ub2f9 timeout (\ucd08)</li> <li><code>--max-retries</code>: \uc7ac\uc2dc\ub3c4 \ud69f\uc218</li> <li><code>--rate-limit</code>: \ucd08\ub2f9 \uc694\uccad \uc218 \uc81c\ud55c</li> <li><code>--trace-prefix</code>: trace_id prefix</li> <li>\ucd9c\ub825</li> <li><code>--output-dir</code>: run \uacb0\uacfc \ud30c\uc77c\uc744 \uc800\uc7a5\ud560 \ub514\ub809\ud130\ub9ac (\ud544\uc218)</li> </ul>"},{"location":"usage/runner/#3-openai-backend-quick-start","title":"3. OpenAI Backend \uc608\uc81c (Quick Start)","text":"<p>Quick Start \uc608\uc81c\uc5d0\uc11c\ub294 OpenAI backend\ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4.</p> <p>\uc804\uc81c:</p> <ul> <li>\ud658\uacbd \ubcc0\uc218 <code>OPENAI_API_KEY</code> (\ud544\uc218)</li> <li>\uc120\ud0dd: <code>OPENAI_BASE_URL</code> (\ucee4\uc2a4\ud140 \uc5d4\ub4dc\ud3ec\uc778\ud2b8 \uc0ac\uc6a9 \uc2dc)</li> </ul> <p>\uc2e4\ud589 \uc608\uc2dc:</p> <pre><code>python -m lm_eval_so.runner.cli \\\n  --dataset example/quickstart/dataset/toy_support_qa_v1 \\\n  --backend openai \\\n  --model gpt-4o-mini \\\n  --param temperature=0 \\\n  --output-dir example/quickstart/runs/openai_gpt-4o-mini\n</code></pre> <p>\uc704 \uba85\ub839\uc740 \ub2e4\uc74c\uc744 \uc218\ud589\ud569\ub2c8\ub2e4.</p> <ul> <li>Dataset \ub514\ub809\ud130\ub9ac(<code>toy_support_qa_v1</code>)\uc5d0\uc11c <code>test.jsonl</code>/<code>metadata.json</code> \ub85c\ub4dc</li> <li><code>backend=openai</code>, <code>model=gpt-4o-mini</code> \uc124\uc815</li> <li>\uac01 \uc0d8\ud50c\uc5d0 \ub300\ud574 OpenAI Chat Completions API \ud638\ucd9c</li> <li>\uc751\ub2f5/latency/status/\uc5d0\ub7ec \uc815\ubcf4\ub97c \ud3ec\ud568\ud55c <code>RunResult</code> \ub808\ucf54\ub4dc\ub97c \uc0dd\uc131</li> <li>\uacb0\uacfc \ud30c\uc77c:</li> <li><code>example/quickstart/runs/openai_gpt-4o-mini/run_results.jsonl</code></li> <li><code>example/quickstart/runs/openai_gpt-4o-mini/run_metadata.json</code></li> </ul>"},{"location":"usage/runner/#4-runresult","title":"4. RunResult\uc5d0 \ud3ec\ud568\ub418\ub294 \uc815\ubcf4","text":"<p>\uc138\ubd80 \ud544\ub4dc\ub294 \ucf54\ub4dc(<code>lm_eval_so.runner.models.RunResult</code>)\ub97c \ucc38\uace0\ud558\uba74 \ub418\uc9c0\ub9cc, \uac1c\ub150\uc801\uc73c\ub85c\ub294 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4.</p> <ul> <li>\uc5b4\ub5a4 \uc0d8\ud50c/\ub370\uc774\ud130\uc14b\uc5d0 \ub300\ud55c \uc2e4\ud589\uc778\uc9c0 (<code>sample_id</code>, <code>dataset_id</code>)</li> <li>\uc5b4\ub5a4 backend/RunConfig\ub85c \uc2e4\ud589\ud588\ub294\uc9c0 (<code>backend</code>, <code>run_config</code>)</li> <li>\uc5b4\ub5a4 \uc694\uccad\uc744 \ubcf4\ub0c8\ub294\uc9c0 (<code>request_messages</code>, <code>request_context</code>)</li> <li>\uc5b4\ub5a4 \uc751\ub2f5\uc744 \ubc1b\uc558\ub294\uc9c0 (<code>response.text</code>, \ud1a0\ud070 \uc0ac\uc6a9\ub7c9 \ub4f1)</li> <li>\uc2e4\ud589 \uc0c1\ud0dc/\uc2dc\uac04/\uc2dc\ub3c4 \ud69f\uc218 (<code>status</code>, <code>latency_ms</code>, <code>attempts</code>)</li> <li>\uc5d0\ub7ec\uac00 \uc788\uc5c8\ub2e4\uba74 \uc5b4\ub5a4 \uc885\ub958\uc778\uc9c0 (<code>error</code> \ud0c0\uc785/\uba54\uc2dc\uc9c0/\uc7ac\uc2dc\ub3c4 \uac00\ub2a5 \uc5ec\ubd80)</li> </ul> <p>\uc774 RunResult\ub97c Evaluator\uac00 \uc18c\ube44\ud558\uc5ec \uba54\ud2b8\ub9ad\uc744 \uacc4\uc0b0\ud558\uac8c \ub429\ub2c8\ub2e4.</p>"},{"location":"usage/runner/#5-runner","title":"5. Runner \uc635\uc158 \uc124\uacc4\uc2dc \uace0\ub824\uc0ac\ud56d","text":"<p>\uc2e4\uc81c \uc11c\ube44\uc2a4\uc5d0 \ubd99\uc774\ub294 \uacbd\uc6b0, \ub2e4\uc74c\uacfc \uac19\uc740 \uc635\uc158 \uc870\ud569\uc744 \uc0c1\ud669\uc5d0 \ub9de\uac8c \uc870\uc808\ud574\uc57c \ud569\ub2c8\ub2e4.</p> <ul> <li><code>max_concurrency</code>: \ubc31\uc5d4\ub4dc\uac00 \uac10\ub2f9 \uac00\ub2a5\ud55c \ub3d9\uc2dc \uc694\uccad \uc218</li> <li><code>timeout</code>: API/\ub124\ud2b8\uc6cc\ud06c \uc0c1\ud669\uc5d0 \ub9de\ub294 \uc801\uc808\ud55c \ud0c0\uc784\uc544\uc6c3</li> <li><code>max_retries</code>: \uc7ac\uc2dc\ub3c4 \uc815\ucc45 (429/5xx \ub4f1\uc5d0 \ub300\ud55c backoff \uc804\ub7b5\uacfc \ud568\uaed8 \uace0\ub824)</li> <li><code>rate_limit</code>: \ucd08\ub2f9 \uc694\uccad/\ud1a0\ud070 \uc81c\ud55c\uc774 \uc788\ub294 API(OpenAI \ub4f1)\uc5d0 \ud544\uc218</li> <li><code>trace_prefix</code>: \ub85c\uadf8/\ubaa8\ub2c8\ud130\ub9c1 \uc2dc\uc2a4\ud15c\uacfc \uc5f0\uacc4\ud560 \ub54c \uc720\uc6a9</li> </ul> <p>Quick Start\uc5d0\uc11c\ub294 \ub2e8\uc21c\uc131\uc744 \uc704\ud574 \uc791\uc740 \ub3d9\uc2dc\uc131 + \uc9e7\uc740 run\ub9cc \uc218\ud589\ud558\uc9c0\ub9cc, \uc2e4\uc81c \ub300\uaddc\ubaa8 \ud14c\uc2a4\ud2b8\uc5d0\uc11c\ub294 \uc704 \uc635\uc158\ub4e4\uc774 \ub9e4\uc6b0 \uc911\uc694\ud574\uc9d1\ub2c8\ub2e4.</p>"},{"location":"usage/runner/#6-pipelinecontext","title":"6. \ud30c\uc774\ud504\ub77c\uc778 \uc720\ud2f8\ub9ac\ud2f0 (PipelineContext)","text":"<p>Runner CLI \uc678\uc5d0 \ud30c\uc774\uc36c \uc2a4\ud06c\ub9bd\ud2b8\ub85c \uc9c1\uc811 \ubcf5\uc7a1\ud55c \ud30c\uc774\ud504\ub77c\uc778(Generation -&gt; Finetuning -&gt; Eval)\uc744 \uad6c\uc131\ud560 \ub54c, MLflow \uad00\ub9ac\ub97c \ub3d5\ub294 <code>PipelineContext</code>\ub97c \uc0ac\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p> <pre><code>from lm_eval_so.utils import PipelineContext\n\n# \uc2e4\ud5d8 \uc774\ub984\uacfc \uc544\ud2f0\ud329\ud2b8 \uc800\uc7a5\uc18c\ub97c \uc9c0\uc815\ud558\uc5ec \ucee8\ud14d\uc2a4\ud2b8 \uc2e4\ud589\nwith PipelineContext(\"my_experiment\", \"output_dir\") as ctx:\n    # \uc804\uc5ed \ud30c\ub77c\ubbf8\ud130 \ub85c\uae45\n    ctx.log_params({\"model\": \"v1.0\"})\n\n    # \uac01 \ub2e8\uacc4\ub97c \uc911\ucca9\ub41c Run(Nested Run)\uc73c\ub85c \uad00\ub9ac\n    with ctx.step(\"step1_generation\") as step_dir:\n        # step_dir \uacbd\ub85c\uc5d0 \ub370\uc774\ud130 \uc0dd\uc131\n        ...\n        # \uc544\ud2f0\ud329\ud2b8 \ubc0f \uba54\ud2b8\ub9ad \ub85c\uae45\n        ctx.log_artifact(\"dataset.jsonl\")\n        ctx.log_metrics({\"count\": 100})\n</code></pre> <p>\uc774\ub97c \ud1b5\ud574 \uad6c\uc870\ud654\ub41c MLflow Run \ud2b8\ub9ac\ub97c \uc190\uc27d\uac8c \uc0dd\uc131\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p>"},{"location":"usage/test-design/","title":"\ud14c\uc2a4\ud2b8 \uc124\uacc4 \ubca0\uc2a4\ud2b8 \ud504\ub799\ud2f0\uc2a4","text":"<p>\uc774 \ubb38\uc11c\ub294 <code>lm-eval-so</code>\ub85c \uc88b\uc740 \ud14c\uc2a4\ud2b8\uc14b/\uc2e4\ud5d8\uc744 \uc124\uacc4\ud558\ub294 \ubc29\ubc95\uc744 \uc815\ub9ac\ud569\ub2c8\ub2e4.</p> <ul> <li>\ud0dc\uadf8/\uae38\uc774/\uc5b8\uc5b4 \ubd84\ud3ec \uc124\uacc4</li> <li>dataset \ubc84\uc804 \uad00\ub9ac \uc6d0\uce59</li> <li>\uc0d8\ud50c\ub9c1 \uc804\ub7b5</li> <li>multi-model \ube44\uad50 \uc2e4\ud5d8 \uc124\uacc4 \ud301</li> </ul>"},{"location":"usage/test-design/#1","title":"1. \ud0dc\uadf8 / \uae38\uc774 / \uc5b8\uc5b4 \ubd84\ud3ec \uc124\uacc4","text":""},{"location":"usage/test-design/#11-tag","title":"1.1 \ud0dc\uadf8(Tag)","text":"<p>\ud0dc\uadf8\ub294 \ub098\uc911\uc5d0 breakdown \uacfc \ubd84\uc11d\uc758 \uae30\uc900\uc774 \ub429\ub2c8\ub2e4.</p> <p>\uad8c\uc7a5 \ud328\ud134:</p> <ul> <li>\uc5ed\ud560\ubcc4 \ud0dc\uadf8</li> <li>\uc608: <code>task:translation</code>, <code>task:summary</code>, <code>task:faq</code></li> <li>\ub3c4\uba54\uc778\ubcc4 \ud0dc\uadf8</li> <li>\uc608: <code>domain:billing</code>, <code>domain:account</code>, <code>domain:search</code></li> <li>\ub09c\uc774\ub3c4/\uc720\ud615 \ud0dc\uadf8</li> <li>\uc608: <code>difficulty:easy/medium/hard</code>, <code>style:formal/casual</code></li> </ul> <p>\uc124\uacc4 \ud301:</p> <ul> <li>\ud55c \uc0d8\ud50c\uc5d0 \uc5ec\ub7ec \ud0dc\uadf8 \ud5c8\uc6a9 (Multi-label)</li> <li>Evaluator\uc758 breakdown.dimensions \uc5d0 <code>\"tag\"</code> \ub97c \ub123\uc5b4\ub450\uba74 \ud0dc\uadf8 \ubcc4 \uc131\ub2a5\uc744 \ubc14\ub85c \ubcfc \uc218 \uc788\uc74c</li> <li>\ud0dc\uadf8 \uc218\ub294 \ub108\ubb34 \ub9ce\uc9c0 \uc54a\uac8c(10~30 \ubc94\uc704) \uad00\ub9ac\ud558\ub294 \uac83\uc774 \ub9ac\ud3ec\ud2b8 \uac00\ub3c5\uc131\uc5d0 \uc88b\uc74c</li> </ul>"},{"location":"usage/test-design/#12-length","title":"1.2 \uae38\uc774(Length)","text":"<p>\ucf54\ub4dc\uc5d0\uc11c\ub294 <code>length_bucket</code> \uc744 <code>short</code> / <code>medium</code> / <code>long</code> \uc73c\ub85c \uc790\ub3d9 \ucd94\ub860\ud569\ub2c8\ub2e4.</p> <ul> <li>\uae30\ubcf8 \uae30\uc900 (\uc608\uc2dc \uad6c\ud604)</li> <li><code>short</code>: content \uae38\uc774 &lt; 200</li> <li><code>medium</code>: 200 &lt;= length &lt; 600</li> <li><code>long</code>: 600 \uc774\uc0c1</li> </ul> <p>\uc124\uacc4 \ud301:</p> <ul> <li>\ud14c\uc2a4\ud2b8\uc14b \uc804\uccb4\uac00 short\uc5d0\ub9cc \ubab0\ub9ac\uc9c0 \uc54a\uac8c, \ucd5c\uc18c\ud55c short/medium/long \uc774 \ubaa8\ub450 \uc77c\uc815 \ube44\uc728 \ub098\uc624\ub3c4\ub85d \uad6c\uc131</li> <li>\uae38\uc774\uc5d0 \ub530\ub77c \ubaa8\ub378 \uc131\ub2a5\uc774 \ub2ec\ub77c\uc9c0\ub294 \uacbd\uc6b0\uac00 \ub9ce\uc73c\ubbc0\ub85c breakdown\uc5d0 <code>length</code> \ub97c \ud56d\uc0c1 \ud3ec\ud568\ud558\ub294 \uac83\uc744 \ucd94\ucc9c</li> </ul>"},{"location":"usage/test-design/#13-language","title":"1.3 \uc5b8\uc5b4(Language)","text":"<p>\uba40\ud2f0 \uc5b8\uc5b4\ub97c \ub2e4\ub8f0 \uacbd\uc6b0:</p> <ul> <li><code>metadata.language</code> \ud544\ub4dc\uc5d0 ISO \ucf54\ub4dc(<code>\"ko\"</code>, <code>\"en\"</code>, <code>\"ja\"</code> \ub4f1)\ub97c \ub123\uace0</li> <li>Evaluator\uc5d0\uc11c breakdown.dimensions \uc5d0 <code>\"language\"</code> \ub97c \ucd94\uac00</li> </ul> <p>\uc124\uacc4 \ud301:</p> <ul> <li>\ud55c \uc5b8\uc5b4\ub9cc \ud14c\uc2a4\ud2b8\ud574\ub3c4, \ub098\uc911\uc744 \uc704\ud574 language \uba54\ud0c0\ub370\uc774\ud130\ub294 \ubbf8\ub9ac \ub123\uc5b4\ub450\ub294 \uac83\uc774 \uc88b\uc74c</li> <li>\ub2e4\uad6d\uc5b4 \ud14c\uc2a4\ud2b8\uc758 \uacbd\uc6b0, \uc5b8\uc5b4\ubcc4 \uc0d8\ud50c \uc218\uac00 \ub108\ubb34 \ubd88\uade0\ud615\ud558\uc9c0 \uc54a\uac8c \uc124\uacc4 (\uc608: ko/en \uac01\uac01 \ucd5c\uc18c N\uac1c \uc774\uc0c1)</li> </ul>"},{"location":"usage/test-design/#2-dataset","title":"2. Dataset \ubc84\uc804 \uad00\ub9ac","text":"<p>Dataset\ub294 \uc7ac\ud604 \uac00\ub2a5\uc131\uc744 \uc704\ud574 <code>dataset_id</code> + <code>version</code> \uc870\ud569\uc73c\ub85c \uad00\ub9ac\ud574\uc57c \ud569\ub2c8\ub2e4.</p> <p>\uad8c\uc7a5 \uc6d0\uce59:</p> <ul> <li><code>dataset_id</code></li> <li>\ub17c\ub9ac\uc801\uc73c\ub85c \ub3d9\uc77c\ud55c \ud14c\uc2a4\ud2b8\uc14b \uacc4\uc5f4\uc5d0 \uacf5\ud1b5\uc73c\ub85c \uc0ac\uc6a9</li> <li>\uc608: <code>toy_support_qa</code>, <code>news_summary_kr</code></li> <li><code>version</code></li> <li>\uc0d8\ud50c \uc9d1\ud569/\uc804\ucc98\ub9ac/\uc0d8\ud50c\ub9c1 \uc804\ub7b5\uc774 \ubc14\ub014 \ub54c\ub9c8\ub2e4 \uc99d\uac00 (<code>v1</code>, <code>v2</code>, <code>v3</code> ...)</li> </ul> <p>\ubc18\ub4dc\uc2dc \ubc84\uc804 \uc62c\ub824\uc57c \ud558\ub294 \ubcc0\uacbd \uc608:</p> <ul> <li>\uc6d0\ucc9c \ub370\uc774\ud130(\ud589/\uc5f4)\uac00 \ubc14\ub010 \uacbd\uc6b0</li> <li>\uc804\ucc98\ub9ac/\ud544\ud130/\uc0d8\ud50c\ub9c1 \ub85c\uc9c1\uc774 \ubc14\ub00c\uc5b4 \uc5b4\ub5a4 \uc0d8\ud50c\uc774 \ud3ec\ud568\ub418\ub294\uc9c0 \ub2ec\ub77c\uc9c4 \uacbd\uc6b0</li> <li>\ud0dc\uadf8/\uc5b8\uc5b4 \ud544\ub4dc \uc815\uc758\uac00 \ud06c\uac8c \ubcc0\uacbd\ub41c \uacbd\uc6b0</li> </ul> <p>\ubc84\uc804 \uc720\uc9c0 \uac00\ub2a5\ud55c \ubcc0\uacbd \uc608 (\uc0c1\ud669\uc5d0 \ub530\ub77c \ub2e4\ub984):</p> <ul> <li>metadata.json \uc5d0 \uc124\uba85 \ud544\ub4dc \ucd94\uac00, tag_stats\ub97c \ub354 \uc790\uc138\ud788 \uc4f0\ub294 \uc815\ub3c4</li> </ul> <p>\uc2e4\ubb34\uc5d0\uc11c\ub294 \uc870\uae08\ub9cc \uc560\ub9e4\ud574\ub3c4 version\uc744 \uc62c\ub9ac\ub294 \ucabd\uc774 \uc548\uc804\ud569\ub2c8\ub2e4.</p>"},{"location":"usage/test-design/#3","title":"3. \uc0d8\ud50c\ub9c1 \uc804\ub7b5","text":"<p>\ub300\uaddc\ubaa8 \uc6d0\ucc9c \ub370\uc774\ud130\uc5d0\uc11c \ud14c\uc2a4\ud2b8\uc14b\uc744 \ucd94\ucd9c\ud560 \ub54c\ub294 \uc0d8\ud50c\ub9c1 \uc804\ub7b5\uc774 \uc911\uc694\ud569\ub2c8\ub2e4.</p>"},{"location":"usage/test-design/#31","title":"3.1 \ub79c\ub364 \uc0d8\ud50c\ub9c1","text":"<ul> <li>\uac00\uc7a5 \ub2e8\uc21c\ud55c \ubc29\ubc95: \uc804\uccb4 \ucf54\ud37c\uc2a4\uc5d0\uc11c \ubb34\uc791\uc704\ub85c N\uac1c \ucd94\ucd9c</li> <li>\uc7a5\uc810: \uad6c\ud604\uc774 \uc27d\uace0, bias\ub97c \uc5b4\ub290 \uc815\ub3c4 \uc0c1\uc1c4</li> <li>\ub2e8\uc810: \ud2b9\uc815 \ucf00\uc774\uc2a4(\uae34 \ubb38\uc7a5, \ud76c\uadc0 \ud0dc\uadf8)\uac00 \ucda9\ubd84\ud788 \ud3ec\ud568\ub418\uc9c0 \uc54a\uc744 \uc218 \uc788\uc74c</li> </ul>"},{"location":"usage/test-design/#32-stratified","title":"3.2 \uacc4\uce35\uc801(Stratified) \uc0d8\ud50c\ub9c1","text":"<ul> <li>\ud0dc\uadf8/\uc5b8\uc5b4/\uae38\uc774 \ub4f1\uc744 \uae30\uc900\uc73c\ub85c \uce35(stratum) \uc744 \ub098\ub208 \ub4a4, \uac01 \uce35\ubcc4\ub85c N\uac1c\uc529 \uc0d8\ud50c\ub9c1</li> <li>\uc608:</li> <li><code>language in {ko, en}</code> \u00d7 <code>length_bucket in {short, medium, long}</code> \uc870\ud569\ubcc4\ub85c \ucd5c\uc18c 10\uac1c\uc529 \ucd94\ucd9c</li> <li>\uc7a5\uc810: breakdown \uad00\uc810\uc5d0\uc11c \ud1b5\uacc4\uac00 \uc548\uc815\ub428</li> </ul>"},{"location":"usage/test-design/#33-edge-case-focus","title":"3.3 \uc9d1\uc911 \uc0d8\ud50c\ub9c1 (Edge-case Focus)","text":"<ul> <li>\ubaa8\ub378\uc774 \uc57d\ud55c \uc601\uc5ed\uc5d0 \uc9d1\uc911\ud55c \ud14c\uc2a4\ud2b8\uc14b\uc744 \ub530\ub85c \ub9cc\ub4dc\ub294 \uc804\ub7b5</li> <li>\uc608:</li> <li><code>long</code> + <code>domain:billing</code> + <code>difficulty:hard</code> \uc870\ud569\ub9cc \ubaa8\uc740 stress test</li> </ul> <p>\uc124\uacc4 \ud301:</p> <ul> <li>\ud558\ub098\uc758 \uac70\ub300\ud55c \ud14c\uc2a4\ud2b8\uc14b \ub9cc\ub4e4\uae30\ubcf4\ub2e4\ub294, \ubaa9\uc801\uc774 \ub2e4\ub978 \uc18c\uaddc\ubaa8 \ud14c\uc2a4\ud2b8\uc14b \uc5ec\ub7ec \uac1c\ub97c \ub9cc\ub4e4\uace0</li> <li>\uc2e4\ud5d8 \ub2e8\uc704(Experiment)\uc5d0\uc11c \uc5b4\ub5a4 \ud14c\uc2a4\ud2b8\uc14b\uc744 \uc0ac\uc6a9\ud560\uc9c0 \uc870\ud569\ud558\ub294 \ubc29\uc2dd\uc774 \uad00\ub9ac\uc5d0 \uc720\ub9ac\ud569\ub2c8\ub2e4.</li> </ul>"},{"location":"usage/test-design/#4-multi-model","title":"4. Multi-model \ube44\uad50 \uc2e4\ud5d8 \uc124\uacc4","text":"<p>\uc5ec\ub7ec \ubaa8\ub378/\uc124\uc815\uc744 \ube44\uad50\ud558\ub824\uba74 \uc2e4\ud5d8 \ub2e8\uc704(Experiment) \ub97c \uba3c\uc800 \uc815\uc758\ud574\uc57c \ud569\ub2c8\ub2e4.</p>"},{"location":"usage/test-design/#41-experiment","title":"4.1 Experiment \ub2e8\uc704 \uc815\uc758","text":"<p><code>Experiment = Dataset \u00d7 Backend \u00d7 RunConfig \u00d7 EvaluatorConfig</code></p> <ul> <li>Dataset: \uc5b4\ub5a4 test.jsonl/metadata.json \uc870\ud569\uc744 \uc37c\ub294\uc9c0</li> <li>Backend: <code>openai</code>, <code>http</code>, <code>local-llm</code> \ub4f1</li> <li>RunConfig: \ubaa8\ub378 \uc774\ub984, decoding \uc124\uc815 \ub4f1</li> <li>EvaluatorConfig: metric/breakdown/report \uc124\uc815</li> </ul> <p>Report\uc5d0\ub294 Experiment \ub2e8\uc704\uac00 \uba85\ud655\ud788 \ub4dc\ub7ec\ub098\uc57c \ud569\ub2c8\ub2e4.</p>"},{"location":"usage/test-design/#42","title":"4.2 \uace0\uc815\ud574\uc57c \ud558\ub294 \uac83\ub4e4","text":"<p>\uacf5\uc815\ud55c \ube44\uad50\ub97c \uc704\ud574 \ub2e4\uc74c\uc740 \uace0\uc815\ud558\ub294 \uac83\uc774 \uc88b\uc2b5\ub2c8\ub2e4.</p> <ul> <li>Dataset (\ub3d9\uc77c\ud55c \uc0d8\ud50c \uc9d1\ud569)</li> <li>EvaluatorConfig (\ub3d9\uc77c\ud55c metric/breakdown \uc124\uc815)</li> </ul> <p>\ubcc0\uacbd\ub418\ub294 \uac83:</p> <ul> <li>Backend/\ubaa8\ub378 (<code>model: gpt-4o-mini</code> vs <code>model: gpt-4.1</code> \ub4f1)</li> <li>RunConfig \ud30c\ub77c\ubbf8\ud130 (temperature \ub4f1)</li> </ul>"},{"location":"usage/test-design/#43-report","title":"4.3 Report \uae30\ubc18 \ube44\uad50","text":"<p>\uc5ec\ub7ec Experiment\uc758 <code>summary.json</code>/<code>report.md</code>\ub97c \ubaa8\uc544 \uc0c1\uc704 \ub808\ubca8 \ub9ac\ud3ec\ud2b8\ub97c \ub9cc\ub4e4 \ub54c\ub294:</p> <ul> <li>\uacf5\ud1b5 \ud14c\uc774\ube14 \ud0a4</li> <li><code>metric</code>, <code>mean</code>, <code>std</code>, <code>sample_count</code></li> <li><code>model_id</code> \ub610\ub294 <code>backend:model</code></li> <li>\ucd94\uac00 \uba54\ud0c0\ub370\uc774\ud130</li> <li><code>dataset_id</code>, <code>dataset_version</code></li> <li><code>prompt_id/prompt_version</code> (LLM Judge\ub97c \uc4f4 \uacbd\uc6b0)</li> </ul> <p>\uc774 \uc815\ubcf4\uac00 \uba85\ud655\ud558\uba74, \ub098\uc911\uc5d0 pandas/\ub178\ud2b8\ubd81\uc73c\ub85c \uc190\uc27d\uac8c \uad50\ucc28 \ubd84\uc11d\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p>"},{"location":"usage/test-design/#5","title":"5. \uc694\uc57d","text":"<ul> <li>\ud0dc\uadf8/\uae38\uc774/\uc5b8\uc5b4 \uba54\ud0c0\ub370\uc774\ud130\ub97c \uc798 \uc124\uacc4\ud574 \ub450\uba74, breakdown \ub9ac\ud3ec\ud2b8\uc758 \ud574\uc11d\ub825\uc774 \ud06c\uac8c \uc62c\ub77c\uac11\ub2c8\ub2e4.</li> <li>Dataset\ub294 <code>dataset_id</code> + <code>version</code> \uc870\ud569\uc73c\ub85c \uc7ac\ud604 \uac00\ub2a5\ud558\uac8c \uad00\ub9ac\ud574\uc57c \ud569\ub2c8\ub2e4.</li> <li>\uc0d8\ud50c\ub9c1\uc740 \ub79c\ub364 + \uacc4\uce35\uc801 + edge-case \uc804\uc6a9 \uc138\ud2b8\ub97c \ud63c\ud569\ud558\ub294 \uc804\ub7b5\uc744 \uad8c\uc7a5\ud569\ub2c8\ub2e4.</li> <li>Multi-model \ube44\uad50 \uc2e4\ud5d8\uc5d0\uc11c\ub294 Experiment \ub2e8\uc704\uc640 Report \uc2a4\ud0a4\ub9c8\ub97c \uc77c\uad00\ub418\uac8c \uc720\uc9c0\ud558\ub294 \uac83\uc774 \uc911\uc694\ud569\ub2c8\ub2e4.</li> </ul>"}]}