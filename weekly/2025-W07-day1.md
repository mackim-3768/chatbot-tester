# Daily Framework Planning – 2025-W07-day1

> Repository: chatbot-tester
> Type: Library / SDK (Generator · Runner · Evaluator)
> Cadence: Daily (주차 내 일차별 사고 기록)
> Focus: Architecture, API design, extensibility, reproducibility

---

## Language Rule (MANDATORY)

- 본 문서의 **모든 내용은 반드시 한국어로 작성**합니다.
- 다음 항목만 예외적으로 영어 사용을 허용합니다:
  - 코드 블록
  - 파일 경로
  - 함수명 / 클래스명 / 모듈명
  - CLI 커맨드
  - 고유 명사 (예: OpenAI, CLI, SDK, Generator, Runner, Evaluator)
- 번역체가 아닌 **기술 기획 문서에 적합한 자연스러운 한국어**를 사용합니다.

---

## 1. Discovery (Ideas)

> Goal: 재사용 가능한 SDK 관점에서의 프레임워크 수준 개선 아이디어를
> **하루 단위로 축적**한다.

### Idea 1
- Affected layer: Generator
- Current limitation: `openai_structure.py`가 OpenAI 클라이언트를 직접 생성하고 있어, Runner 모듈의 유연한 Backend 시스템(`ChatBackend`)을 활용하지 못함. 이로 인해 다른 LLM 제공자를 사용한 데이터 생성이 불가능하고 코드가 중복됨.
- Proposed improvement: Generator가 Runner의 `ChatBackend` 인터페이스를 통해 데이터 생성 요청을 수행하도록 리팩토링.
- Why this matters for an SDK: 프레임워크 전반의 일관성을 유지하고, 사용자가 정의한 커스텀 백엔드(예: 로컬 vLLM, Azure 등)를 데이터 생성에도 활용할 수 있게 됨.

### Idea 2
- Affected layer: Runner
- Current limitation: `run_async_job`이 모든 결과를 메모리에 모은(`asyncio.gather`) 후 반환하는 구조라, 대규모 데이터셋(예: 10만 건 이상) 처리 시 OOM 위험이 있음.
- Proposed improvement: 실행 결과를 실시간으로 디스크에 스트리밍하거나, `Yield` 패턴을 지원하는 `run_stream_job` 도입.
- Why this matters for an SDK: 프로덕션 레벨의 대규모 평가 수행 시 안정성과 확장성을 보장함.

### Idea 3
- Affected layer: Evaluator
- Current limitation: 메트릭 등록이 파이썬 코드를 통해서만 가능하여, CLI 사용자나 비개발자가 외부 스크립트에 정의된 메트릭을 동적으로 불러오기 어려움.
- Proposed improvement: 파일 경로나 모듈 경로를 인자로 받아 메트릭을 동적으로 로드하는 플러그인 로더 추가.
- Why this matters for an SDK: 사용자가 라이브러리 코드를 수정하지 않고도 자체 평가 로직을 쉽게 확장/적용할 수 있음.

### Idea 4
- Affected layer: Evaluator (Report)
- Current limitation: 리포트가 단일 실행 결과에 대한 분석에 집중되어 있어, 프롬프트나 모델 변경 전후의 성능 비교(A/B 테스트)가 어려움.
- Proposed improvement: 두 개의 Run ID를 입력받아 지표 변화와 응답 차이를 시각화하는 'Comparison Report' 기능 추가.
- Why this matters for an SDK: 챗봇 개발 사이클에서 가장 빈번한 "이 변경이 성능을 향상시켰는가?"라는 질문에 직접적인 답을 줄 수 있음.

### Idea 5
- Affected layer: Generator / Runner
- Current limitation: Generator는 동기(`sync`) 방식이고 Runner는 비동기(`async`) 방식이라 실행 모델이 파편화되어 있음.
- Proposed improvement: Generator의 생성 파이프라인도 `async` 기반으로 전환하여 Runner의 동시성 제어 및 재시도 로직(`runner_core`)을 공통으로 사용.
- Why this matters for an SDK: 코드 베이스의 실행 모델을 통일하여 유지보수성을 높이고, 데이터 생성 속도를 극대화할 수 있음.

---

## 2. Triage

> Goal: **오늘 기준** 가장 아키텍처적 파급력이 큰 1개 아이디어를 선정한다.

### Selected Idea
- Title: Generator와 Runner의 Backend 통합 (Unify Generator and Runner Backends)
- Primary affected layer(s): Generator, Runner

### Selection Rationale
- Architectural leverage: Generator가 Runner의 인프라(Backend)를 재사용하게 함으로써, "외부 시스템 연동은 Adapter를 통한다"는 아키텍처 원칙을 강제하고 코드 중복을 제거함.
- Impact on extensibility / reuse: 단순히 OpenAI뿐만 아니라, Runner가 지원하는 모든 모델(Claude, Local LLM 등)을 합성 데이터 생성에 바로 사용할 수 있게 됨.
- Reduction of future complexity: 향후 새로운 LLM 지원 시 Runner 쪽만 업데이트하면 Generator도 자동으로 지원하게 되므로 유지보수 비용이 절감됨.

### Deferred Ideas (Brief)
- Idea 2 (Streaming): 중요하지만 현재 데이터 규모에서는 메모리가 큰 병목이 아님. 다음 스프린트로 연기.
- Idea 4 (Comparison Report): 시각화 개선은 로직 통합 이후에 진행하는 것이 효율적임.

---

## 3. Spec Draft (Top 1 Only)

### Feature / Improvement Name
Generator Backend Integration (`ChatBackend` 도입)

### Problem Statement
- 현재 `synthetic/openai_structure.py`는 `openai.OpenAI` 클라이언트를 직접 인스턴스화하여 사용함.
- 이로 인해 `runner/backends`에 정의된 풍부한 재시도 로직, 로깅, 그리고 다른 모델(Azure, vLLM 등) 지원 기능을 활용할 수 없음.
- 사용자가 데이터 생성을 위해 별도의 OpenAI API 키 설정을 중복으로 관리해야 함.

### Design Approach (High-level)
- Core concept: Generator의 데이터 생성 요청을 `ChatBackend.send()` 호출로 추상화함.
- Key abstractions or interfaces:
  - `generate_structured_synthetic_dataset` 함수가 `backend_name` 또는 설정된 `ChatBackend` 인스턴스를 사용하도록 변경.
  - 기존의 `_request_batch` 함수 내부 로직을 `RunRequest` 생성 및 `backend.send()` 호출로 대체.
- Expected behavior: 사용자가 CLI나 API를 통해 "생성 모델"로 "azure-gpt4" 등을 지정하면, Runner에 등록된 해당 백엔드를 통해 데이터가 생성됨.

### MVP Scope
- Included in MVP:
  - `synthetic/openai_structure.py`에서 직접적인 `openai` 패키지 의존성 제거 (타입 힌트 제외).
  - `ChatBackend`를 사용하여 구조화된 데이터(JSON 모드) 요청 처리.
  - `runner_core`의 비동기 실행 흐름을 활용하기 위해 Generator 내부 루프를 `async`로 전환하거나 `asyncio.run`으로 래핑.
- Explicitly excluded:
  - 스트리밍 방식의 데이터 생성 (배치 단위 생성 유지).
  - OpenAI 외 타 벤더의 JSON 모드 호환성 완벽 보장 (우선 OpenAI 호환 백엔드만 타겟).

### Optional / Future Extensions
- 다양한 모델의 "JSON 강제" 프롬프트 전략을 백엔드별로 다르게 적용.
- 데이터 생성 과정의 진행률 표시(Progress bar)를 Runner의 이벤트 시스템과 통합.

### Acceptance Criteria
- [ ] `generate_structured_synthetic_dataset` 함수 호출 시 `ChatBackend`를 통해 API 요청이 전송됨.
- [ ] 기존과 동일하게 `response_format={"type": "json_object"}` 옵션이 정상 동작하여 JSON 데이터가 생성됨.
- [ ] `OPENAI_API_KEY` 환경변수 외에 Runner 설정(예: `backend_options`)을 통해 인증 정보를 주입할 수 있음.
- [ ] 생성된 데이터셋의 메타데이터에 사용된 백엔드 정보가 정확히 기록됨.

---

## 4. Backlog Draft (Issue-Level)

### Suggested GitHub Issue Title
`[Framework][Daily][2025-W07-day1] Generator와 Runner의 Backend 의존성 통합`

### Task Breakdown
- [ ] Core implementation
  - Module: `src/chatbot_tester/generator/synthetic`
  - Summary: `openai_structure.py`를 리팩토링하여 `ChatBackend`를 사용하도록 수정. `_generate_samples_via_openai`를 비동기 호환 구조로 변경.
- [ ] CLI changes (if any)
  - Command: `chatbot-tester generate` (가상의 명령어)
  - Flags / options: `--backend` 옵션 추가 (기존 `--model` 옵션과 연동).
- [ ] API impact
  - Breaking change: No (내부 구현 변경 위주이나, 함수 시그니처에 `backend` 인자 추가 필요).
  - Migration needed: No (기본값으로 OpenAI 백엔드를 자동 선택하도록 처리).
- [ ] Tests
  - Unit / Integration: Mock Backend를 주입하여 Generator가 올바른 `RunRequest`를 생성하는지 검증하는 테스트 추가.
- [ ] Documentation
  - README / Examples / Docstrings: Generator에서 커스텀 백엔드를 사용하는 예제 코드 추가.

### Notes
- Backward compatibility concerns: 기존 함수 파라미터(`openai_model`)를 유지하되 내부적으로 백엔드 설정으로 매핑해야 함.
- Refactoring risk: Generator는 현재 동기 방식, Backend는 비동기 방식이므로 `asyncio` 이벤트 루프 관리에 주의 필요.

---

## 5. Docs / Notes

### README Updates
- 추가 또는 수정할 섹션: `Generator` 사용법 섹션.
- 전달하고자 하는 핵심 메시지: "이제 Generator에서도 Runner와 동일한 백엔드 설정을 공유하여, 다양한 LLM을 소스로 데이터를 생성할 수 있습니다."

### Example Snippet (Optional)

```python
# Example usage
from chatbot_tester.generator import generate_structured_synthetic_dataset
from chatbot_tester.runner.backends import register_backend, ChatBackend

# 커스텀 백엔드 등록 (예: 로컬 vLLM)
@register_backend("local_vllm")
class LocalVLLMBackend(ChatBackend):
    ...

# 등록된 백엔드를 사용하여 데이터 생성
dataset_path = generate_structured_synthetic_dataset(
    dataset_id="my_dataset",
    backend_name="local_vllm",  # Runner의 백엔드 재사용
    sample_count=50,
    # ...
)
```
