# Daily Framework Planning – 2025-W06-Day1

> Repository: chatbot-tester
> Type: Library / SDK (Generator · Runner · Evaluator)
> Cadence: Daily (주차 내 일차별 사고 기록)
> Focus: Architecture, API design, extensibility, reproducibility

---

## 1. Discovery (Ideas)

> Goal: 재사용 가능한 SDK 관점에서의 프레임워크 수준 개선 아이디어를
> **하루 단위로 축적**한다.

### Idea 1: LLM 백엔드 레지스트리의 Common 계층 통합 (Centralized LLM Backend Registry)
- **Affected layer**: Common (Generator, Runner, Evaluator 모두 영향)
- **Current limitation**: 현재 `runner` 모듈에만 `ChatBackend`와 `BackendRegistry`가 존재함. 반면 `generator`(데이터 생성)와 `evaluator`(LLM-as-a-judge)는 `OpenAI` 클라이언트를 내부적으로 직접 인스턴스화하여 사용하고 있어, 다른 LLM(Azure, Anthropic, Local LLM)으로 교체하거나 테스트 시 Mocking하기가 매우 어려움.
- **Proposed improvement**: `src/chatbot_tester/runner/backends` 패키지를 `src/chatbot_tester/common/backends`로 이동하여 중앙화함. Generator와 Evaluator가 이 레지스트리를 통해 백엔드 인스턴스를 주입받도록 리팩토링함.
- **Why this matters for an SDK**: 사용자가 한 번 정의한 백엔드 설정(예: 사용자 지정 모델, 인증 정보)을 데이터 생성, 실행, 평가의 모든 단계에서 일관되게 재사용할 수 있음. "Bring Your Own Backend" 원칙 실현.

### Idea 2: 비동기(Async) I/O 전략 표준화 (Unified Async Strategy)
- **Affected layer**: Common / Core
- **Current limitation**: `runner`는 `asyncio` 기반으로 동작하지만, `generator`와 `evaluator`의 일부 로직은 동기(Sync) 방식을 혼용하고 있을 가능성이 큼. 대규모 데이터셋 처리 시 성능 병목이 발생하며, 호출 방식이 통일되지 않아 SDK 사용자에게 혼란을 줌.
- **Proposed improvement**: LLM 호출 등 모든 I/O 바운드 작업에 대해 `async/await` 패턴을 표준으로 채택하고, 필요한 경우 동기 래퍼를 제공.
- **Why this matters for an SDK**: 대량의 요청을 처리해야 하는 테스트 프레임워크 특성상 높은 동시성(Concurrency) 처리가 필수적임.

### Idea 3: 이벤트 기반 관측성 (Event-Driven Observability)
- **Affected layer**: Common
- **Current limitation**: 실행 진행 상황, 오류, 중간 결과 등이 단순 `print` 문이나 파편화된 로깅으로 처리됨. CLI의 Progress Bar나 웹 대시보드 등 다양한 출력 인터페이스를 지원하기 어려움.
- **Proposed improvement**: 경량 `EventBus`를 도입하여 내부 상태 변화(예: `SampleGenerated`, `RunCompleted`)를 이벤트로 발행하고, 핸들러가 이를 소비하여 로깅이나 UI 업데이트를 수행하도록 분리.
- **Why this matters for an SDK**: 라이브러리 사용자가 로깅 방식을 커스터마이징하거나 자체 모니터링 시스템에 연동하기 쉽게 만듦.

### Idea 4: 아티팩트 스토리지 추상화 (Artifact Storage Abstraction)
- **Affected layer**: Common
- **Current limitation**: 데이터셋 입출력 및 리포트 저장이 로컬 파일 시스템 경로(`pathlib.Path`)에 강하게 결합되어 있음. 클라우드 스토리지(S3, GCS) 연동이 어렵고 경로 관리가 수동적임.
- **Proposed improvement**: `ArtifactStore` 추상 클래스를 정의하고 `get_reader()`, `get_writer()` 등의 인터페이스를 제공. 로컬 파일 시스템은 하나의 구현체로 취급.
- **Why this matters for an SDK**: 클라우드 네이티브 환경(예: Kubernetes Job, Lambda)에서의 실행 유연성을 확보함.

### Idea 5: 테스트 샘플 스키마(TestSample Schema) 엄격화
- **Affected layer**: Common
- **Current limitation**: `TestSample` 객체와 딕셔너리(`dict`) 형태가 혼용되어 사용되는 경우가 있음. 특히 메타데이터 필드가 비정형적이어서 단계 간 데이터 전달 시 유효성 검증이 누락될 수 있음.
- **Proposed improvement**: 모든 데이터 교환 객체(DTO)를 Pydantic 모델로 엄격하게 정의하고, 직렬화/역직렬화 로직을 중앙화함.
- **Why this matters for an SDK**: 타입 안전성을 보장하여 개발자 경험(DX)을 향상시키고 런타임 에러를 줄임.

---

## 2. Triage

> Goal: **오늘 기준** 가장 아키텍처적 파급력이 큰 1개 아이디어를 선정한다.

### Selected Idea
- **Title**: LLM 백엔드 레지스트리의 Common 계층 통합 (Centralized LLM Backend Registry)
- **Primary affected layer(s)**: Common, Runner, Generator, Evaluator

### Selection Rationale
- **Architectural leverage**: 현재 코드 중복(OpenAI 클라이언트 생성 로직)을 제거하고, 프레임워크 전반의 의존성 흐름을 단방향(Component -> Common)으로 정리할 수 있음.
- **Impact on extensibility / reuse**: 사용자가 커스텀 백엔드(예: 사내 LLM)를 하나만 등록하면 데이터 생성부터 평가까지 모든 단계에서 즉시 사용할 수 있게 됨.
- **Reduction of future complexity**: 각 모듈별로 서로 다른 LLM 연동 코드를 유지보수할 필요가 없어짐.

### Deferred Ideas (Brief)
- **비동기 표준화**: 중요하지만, 백엔드 구조가 정리된 후에 적용하는 것이 효율적임. (백엔드 인터페이스 변경 시 함께 고려 가능)
- **이벤트 기반 관측성**: 기능적 요구사항보다는 운영 편의성 개선이므로 우선순위가 낮음.
- **스토리지 추상화**: 로컬 실행이 주된 현재 단계에서는 파일 시스템으로 충분함.

---

## 3. Spec Draft (Top 1 Only)

### Feature / Improvement Name
**Centralized LLM Backend Registry & Common Adapters**

### Problem Statement
- **현재 상황**: `runner` 모듈은 확장 가능한 `BackendRegistry`를 가지고 있으나, `generator`와 `evaluator`는 `openai` 라이브러리를 직접 임포트하여 하드코딩된 로직으로 사용 중임.
- **문제점**: 사용자가 `runner`에 커스텀 백엔드를 등록해도 데이터 생성이나 평가 단계에서는 사용할 수 없음. 또한 `generator`와 `evaluator` 테스트 시 실제 API 호출을 Mocking하기 어려움.
- **대상**: 라이브러리 사용자 (커스텀 LLM 연동 필요), 유지보수자 (중복 코드 관리).

### Design Approach (High-level)
- **Core concept**: `ChatBackend` 인터페이스와 `BackendRegistry`를 모든 모듈이 접근 가능한 `chatbot_tester.common.backends`로 이동.
- **Key abstractions**:
  - `ChatBackend` (Interface): `send(request) -> response` 메서드 정의.
  - `BackendRegistry`: 백엔드 클래스 등록 및 팩토리 역할.
  - `Generator` 및 `Evaluator` 어댑터: 레지스트리에서 백엔드를 가져와 사용하는 래퍼 구현.
- **Expected behavior**:
  ```python
  from chatbot_tester.common.backends import backend_registry

  # Generator에서
  backend = backend_registry.create("openai", **config)
  response = await backend.send(prompt)
  ```

### MVP Scope
- **Included in MVP**:
  - `src/chatbot_tester/runner/backends/` 내용을 `src/chatbot_tester/common/backends/`로 이동.
  - 기존 `runner` 코드가 새로운 위치를 참조하도록 수정.
  - `generator/synthetic` 로직을 수정하여 직접 `OpenAI()`를 호출하는 대신 `BackendRegistry` 사용.
  - `evaluator/metrics` (Active LLM Judge) 로직을 수정하여 `BackendRegistry` 사용.
- **Explicitly excluded**:
  - 비동기/동기 호출 방식의 완전한 통일 (일단 기존 방식에 맞춰 어댑터 적용).
  - 스트리밍 지원 (MVP에서는 전체 응답 반환만 고려).

### Optional / Future Extensions
- 백엔드별 비용(Cost) 및 토큰 사용량(Token Usage) 집계 표준화.
- 로컬 LLM(HuggingFace Transformers) 백엔드 기본 제공 추가.

### Acceptance Criteria
- [ ] `runner/backends` 코드가 `common/backends`로 이동됨.
- [ ] `generator`가 `openai_structure.py`에서 하드코딩된 `OpenAI` 클라이언트 대신 레지스트리를 통해 백엔드를 호출함.
- [ ] `evaluator`의 `ActiveLLMJudgeMetric`이 레지스트리를 통해 백엔드를 호출함.
- [ ] 기존 Runner 테스트 및 Generator/Evaluator 동작이 깨지지 않음 (Refactoring).

---

## 4. Backlog Draft (Issue-Level)

### Suggested GitHub Issue Title
`[Refactor] Centralize LLM Backend Registry to Common Layer`

### Task Breakdown
- [ ] **Core implementation**
  - Module: `chatbot_tester.common.backends`
  - Summary: `runner.backends`의 `base.py`, `openai.py` 등을 이동. `runner`가 이를 임포트하도록 수정.
- [ ] **Generator Refactoring**
  - Module: `chatbot_tester.generator.synthetic`
  - Summary: `_get_openai_client` 제거 및 `BackendRegistry` 활용 로직으로 대체. 프롬프트 구성 로직과 호출 로직 분리.
- [ ] **Evaluator Refactoring**
  - Module: `chatbot_tester.evaluator.metrics.active_llm_judge`
  - Summary: `ActiveLLMJudgeMetric` 초기화 시 `backend_name`을 받아 레지스트리에서 로드하도록 변경.
- [ ] **API Impact Check**
  - Breaking change: Yes (내부 API 이동). Runner의 공개 API(`run_job`)는 유지되나, 백엔드 직접 임포트 경로는 변경됨.
  - Migration needed: Yes (커스텀 백엔드 사용자).
- [ ] **Tests**
  - Unit: 이동된 백엔드 모듈에 대한 테스트. Generator/Evaluator가 Mock 백엔드로 동작하는지 테스트 추가.

### Notes
- **Backward compatibility**: `chatbot_tester.runner.backends`에서 `common.backends`를 임포트하여 다시 내보내기(Re-export)하면 하위 호환성을 유지할 수 있음. (`from .common.backends import ChatBackend` 등)

---

## 5. Docs / Notes

### README Updates
- **섹션**: "Custom Backends"
- **내용**: 백엔드 등록 방식이 `runner` 전용이 아니라 프레임워크 전체(Generator, Evaluator 포함)에 적용됨을 명시.

### Example Snippet (Optional)

```python
# 사용자 지정 백엔드 등록 예시
from chatbot_tester.common.backends import ChatBackend, register_backend

@register_backend("my_custom_llm")
class MyBackend(ChatBackend):
    async def send(self, request):
        return "Custom response"

# 이제 Generator와 Runner 모두에서 "my_custom_llm" 사용 가능
```
